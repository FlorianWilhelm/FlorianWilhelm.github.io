<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Hive UDFs and UDAFs with Python - Florian Wilhelm's blog</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="https://florianwilhelm.info/2016/10/python_udf_in_hive/">

        <meta name="author" content="Florian Wilhelm" />
        <meta name="keywords" content="python,hadoop,hive,big data" />
        <meta name="description" content="Sometimes the analytical power of built-in Hive functions is just not enough. In this case it is possible to write hand-tailored User-Defined Functions (UDFs) for transformations and even aggregations which are therefore called User-Defined Aggregation Functions (UDAFs). In this post we focus on how to write sophisticated UDFs and UDAFs …" />

        <meta property="og:site_name" content="Florian Wilhelm's blog" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Hive UDFs and UDAFs with Python"/>
        <meta property="og:url" content="https://florianwilhelm.info/2016/10/python_udf_in_hive/"/>
        <meta property="og:description" content="Sometimes the analytical power of built-in Hive functions is just not enough. In this case it is possible to write hand-tailored User-Defined Functions (UDFs) for transformations and even aggregations which are therefore called User-Defined Aggregation Functions (UDAFs). In this post we focus on how to write sophisticated UDFs and UDAFs …"/>
        <meta property="article:published_time" content="2016-10-23" />
            <meta property="article:section" content="post" />
            <meta property="article:tag" content="python" />
            <meta property="article:tag" content="hadoop" />
            <meta property="article:tag" content="hive" />
            <meta property="article:tag" content="big data" />
            <meta property="article:author" content="Florian Wilhelm" />

    <meta name="twitter:dnt" content="on">
    <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@FlorianWilhelm">
        <meta name="twitter:creator" content="@FlorianWilhelm">
    <meta name="twitter:domain" content="https://florianwilhelm.info">


    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://florianwilhelm.info/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="https://florianwilhelm.info/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://florianwilhelm.info/theme/css/pygments/native.css" rel="stylesheet">
        <link href="https://florianwilhelm.info/theme/css/typogrify.css" rel="stylesheet">
    <link rel="stylesheet" href="https://florianwilhelm.info/theme/css/style.css" type="text/css"/>


        <link href="https://florianwilhelm.info/feeds/post.atom.xml" type="application/atom+xml" rel="alternate"
              title="Florian Wilhelm's blog post ATOM Feed"/>
</head>
<body>

<div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://florianwilhelm.info/" class="navbar-brand">
Florian Wilhelm's blog            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/about/">About me</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><a href="https://florianwilhelm.info/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="https://florianwilhelm.info/2016/10/python_udf_in_hive/"
                       rel="bookmark"
                       title="Permalink to Hive UDFs and UDAFs with Python">
                        Hive UDFs and UDAFs with&nbsp;Python
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2016-10-23T11:00:00+02:00"> Oct. 23, 2016</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="https://florianwilhelm.info/tag/python/">python</a>
        /
	<a href="https://florianwilhelm.info/tag/hadoop/">hadoop</a>
        /
	<a href="https://florianwilhelm.info/tag/hive/">hive</a>
        /
	<a href="https://florianwilhelm.info/tag/big-data/">big data</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>Sometimes the analytical power of <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF">built-in Hive functions</a> is just not enough.
In this case it is possible to write hand-tailored User-Defined Functions (UDFs)
for transformations and even aggregations which are therefore called User-Defined
Aggregation Functions (UDAFs). In this post we focus on how to write sophisticated
UDFs and UDAFs in Python. By sophisticated we mean that our <span class="caps">UD</span>(A)Fs should
also be able to leverage external libraries like Numpy, Scipy, Pandas etc.
This makes things a lot more complicated since we have to provide not only some
Python script but also a full-blown virtual environment including the external
libraries since they may not be available on the cluster nodes.
Therefore, in this tutorial we require only that a basic installation of Python
is available on the data nodes of the Hive&nbsp;cluster.</p>
<h2>General&nbsp;information</h2>
<p>To keep the idea behind <span class="caps">UD</span>(A)Fs short, only some general notes are mentioned here.
With the help of the <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Transform">Transform/Map-Reduce syntax</a>, i.e. <code>TRANSFORM</code>, it is
possible to plug in your own custom mappers and reducers. This is where we gonna hook
in our Python script. A <span class="caps">UDF</span> is basically only a transformation done by a mapper
meaning that each row should be mapped to exactly one row. A <span class="caps">UDAF</span> on the
other hand allows us to transform a group of rows into one or more rows, meaning that we
can reduce the number of input rows to a single output row by some custom
aggregation. We can control if the script is run in a mapper or reducer step
by the way we formulate our HiveQL query. The statements <code>DISTRIBUTE BY</code> and
<code>CLUSTER BY</code> allow us to indicate that we want to actually perform an aggregation.
HiveQL feeds the data to the Python script or any other custom script by using
the standard input and reads the result from its standard out. All messages from
standard error are ignored and can therefore be used for debugging.
Since a <span class="caps">UDAF</span> is more complex than a <span class="caps">UDF</span> and actually can be seen as a generalization
of it, the development of a <span class="caps">UDAF</span> is demonstrated&nbsp;here.   </p>
<h2>Overview and a little&nbsp;task</h2>
<p>In order to not get lost in the details, here is what we want to achieve from
a high-level&nbsp;perspective.</p>
<ol>
<li>Set up small example Hive table within some&nbsp;database.</li>
<li>Create a virtual environment and upload it to Hive&#8217;s distributed&nbsp;cache.</li>
<li>Write the actual <span class="caps">UDAF</span> as Python script and a little helper shell&nbsp;script.</li>
<li>Write a HiveQL query that feeds our example table into the Python&nbsp;script.</li>
</ol>
<p>Our dummy data consists of different types of vehicles (car or bike) and a price. For
each category we want to calculate the mean and the standard deviation with the help
of Pandas to keep things simple. It should not be necessary to mention that this
task can be handled in HiveQL directly, so this is really only for&nbsp;demonstration.</p>
<h2>1. Setting up our dummy&nbsp;table</h2>
<p>With the following query we generate our sample&nbsp;data:</p>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">tmp</span><span class="p">;</span>
<span class="n">USE</span> <span class="n">tmp</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="p">(</span><span class="n">id</span> <span class="nb">INT</span><span class="p">,</span> <span class="n">vtype</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">price</span> <span class="nb">FLOAT</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="ss">&quot;car&quot;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="ss">&quot;car&quot;</span><span class="p">,</span> <span class="mi">42</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="ss">&quot;car&quot;</span><span class="p">,</span> <span class="mi">10000</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="ss">&quot;car&quot;</span><span class="p">,</span> <span class="mi">69</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="ss">&quot;bike&quot;</span><span class="p">,</span> <span class="mi">1426</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="ss">&quot;bike&quot;</span><span class="p">,</span> <span class="mi">32</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="ss">&quot;bike&quot;</span><span class="p">,</span> <span class="mi">1234</span><span class="p">.);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">foo</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="ss">&quot;bike&quot;</span><span class="p">,</span> <span class="k">null</span><span class="p">);</span>
</code></pre></div>

<p>Note that the last row even contains a null value that we need to handle&nbsp;later.</p>
<h2>2. Creating and uploading a virtual&nbsp;environment</h2>
<p>In order to prepare a proper virtual environment we need to execute the following
steps on an <span class="caps">OS</span> that is binary compatible to the <span class="caps">OS</span> on the Hive cluster. Typically
any recent 64bit Linux distribution will&nbsp;do.</p>
<p>We start by creating an empty virtual environment&nbsp;with:</p>
<blockquote>
<p>virtualenv &#8212;no-site-packages -p /usr/bin/python3&nbsp;venv</p>
</blockquote>
<p>assuming that <code>virtualenv</code> was already installed with the help of pip. Note that
we explicitly ask for Python 3. Who uses Python 2 these days&nbsp;anyhow?</p>
<p>The problem with the <code>activate</code> script of a virtual environment is that 
its path is hard-coded. We change that by replacing the&nbsp;line </p>
<div class="highlight"><pre><span></span><code><span class="nv">VIRTUAL_ENV</span><span class="o">=</span><span class="s2">&quot;your/path/to/venv&quot;</span>
</code></pre></div>

<p>with</p>
<div class="highlight"><pre><span></span><code><span class="nv">HERE</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span> <span class="nb">cd</span> <span class="s2">&quot;</span><span class="k">$(</span> dirname <span class="s2">&quot;</span><span class="si">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">)</span><span class="s2">&quot;</span> <span class="o">&amp;&amp;</span> <span class="nb">pwd</span> <span class="k">)</span><span class="s2">&quot;</span>
<span class="nv">VIRTUAL_ENV</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span> readlink -f <span class="s2">&quot;</span><span class="si">${</span><span class="nv">HERE</span><span class="si">}</span><span class="s2">/../&quot;</span> <span class="k">)</span><span class="s2">&quot;</span>
</code></pre></div>

<p>in <code>./venv/bin/activate</code>. Additionally, we replace in <code>pip</code> the shebang line, i.e.&nbsp;replacing</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/your/path/to/venv/venv/bin/python3</span>
</code></pre></div>

<p>with</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/usr/bin/env python</span>
</code></pre></div>

<p>This will help us later when we call <code>pip list</code> for debugging&nbsp;reasons.</p>
<p>We activate the virtual environment and install Pandas in&nbsp;it.</p>
<blockquote>
<p>source&nbsp;venv/bin/activate</p>
<p>pip install numpy&nbsp;pandas</p>
</blockquote>
<p>This should install Pandas and all its dependencies into our virtual environment.
No we package the virtual environment for later deployment in the distributed&nbsp;cache:</p>
<blockquote>
<p>cd&nbsp;venv</p>
<p>tar cvfhz ../venv.tgz&nbsp;./</p>
<p>cd&nbsp;..</p>
</blockquote>
<p>Be aware that the archive was created with the actual content at its root so
when unpacking there will be no directory holding the actual content. We also
used the parameter <code>h</code> to package linked&nbsp;files.</p>
<p>Now we push the archive to <span class="caps">HDFS</span> so that later Hive&#8217;s data nodes will be able to
find&nbsp;it:</p>
<blockquote>
<p>hdfs dfs -put venv.tgz&nbsp;/tmp</p>
</blockquote>
<p>The directory <code>/tmp</code> should be changed accordingly. One should also note that
in principle the same procedure should also be possible with conda environments. In
practice though, it might be a bit more involved since the activation of a conda
environment (what we need to do later) assumes an installation of at least
miniconda which might not be available on the data&nbsp;nodes.</p>
<h2>3. Writing and uploading the&nbsp;scripts</h2>
<p>We start by writing a simple Python script <code>udaf.py</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">groupby</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">SEP</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span>
<span class="n">NULL</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\\</span><span class="s1">N&#39;</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">read_input</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">SEP</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">read_input</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groupby</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reading group </span><span class="si">{}</span><span class="s2">...&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vtype</span><span class="p">))</span>
        <span class="n">group</span> <span class="o">=</span> <span class="p">[(</span><span class="nb">int</span><span class="p">(</span><span class="n">rowid</span><span class="p">),</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="n">price</span> <span class="o">==</span> <span class="n">NULL</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="n">price</span><span class="p">))</span>
                 <span class="k">for</span> <span class="n">rowid</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">price</span> <span class="ow">in</span> <span class="n">group</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;vtype&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">vtype</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">SEP</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">output</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div>

<p>The script should be pretty much self-explanatory. We read from the standard
input with the help of a generator that strips and splits the lines by the
separator <code>\t</code>. At any point we want to avoid to have more data in memory as
needed to perform the actual computation. We use the <code>groupby</code> function that
is shipped with Python to iterate over our two types of vehicles. For each group
we convert the read values to their respective data types and at that point
also take care of <code>null</code> values which are encoded as <code>\N</code>. After this preprocessing
we finally feed everything into a Pandas dataframe, do our little mean and standard
deviation calculations and print everything as a tabular separated list.
It should also be noted that we set up a logger at the beginning which writes
everything to standard error. This really helps a lot with debugging and should
be used. For demonstration purposes the vehicle type of the group currently
processed is&nbsp;printed.</p>
<p>At this point we would actually be done if it wasn&#8217;t for the fact that we are
importing external libraries like Pandas. So if we ran this Python script directly
as <span class="caps">UDAF</span> we would see import errors if Pandas is not installed on all cluster nodes.
But in the spirit of David Wheeler&#8217;s &#8220;All problems in computer science can be
solved by another level of indirection.&#8221; we just write a little helper script
called <code>udaf.sh</code> that does this job for us and calls the Python script&nbsp;afterwards.</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="nb">set</span> -e
<span class="o">(</span>&gt;<span class="p">&amp;</span><span class="m">2</span> <span class="nb">echo</span> <span class="s2">&quot;Begin of script&quot;</span><span class="o">)</span>
<span class="nb">source</span> ./venv.tgz/bin/activate
<span class="o">(</span>&gt;<span class="p">&amp;</span><span class="m">2</span> <span class="nb">echo</span> <span class="s2">&quot;Activated venv&quot;</span><span class="o">)</span>
<span class="o">(</span>&gt;<span class="p">&amp;</span><span class="m">2</span> pip list --format<span class="o">=</span>columns --no-cache-dir<span class="o">)</span>
python udaf.py
<span class="o">(</span>&gt;<span class="p">&amp;</span><span class="m">2</span> <span class="nb">echo</span> <span class="s2">&quot;End of script&quot;</span><span class="o">)</span>
</code></pre></div>

<p>Again we use standard error to trace what the script is currently doing.
Furthermore, we use <code>pip list</code> to output the content of the virtual environment
for debugging reasons.
With the help of <code>chmod u+x</code> we make the script executable and now all that&#8217;s
left is to push both files somewhere on <span class="caps">HDFS</span> for the cluster to&nbsp;find:</p>
<blockquote>
<p>hdfs dfs -put udaf.py&nbsp;/tmp</p>
<p>hdfs dfs -put udaf.sh&nbsp;/tmp</p>
</blockquote>
<h2>4. Writing the actual HiveQL&nbsp;query</h2>
<p>After we are all prepared and set we can write the actual HiveQL&nbsp;query:</p>
<div class="highlight"><pre><span></span><code><span class="k">DELETE</span> <span class="n">ARCHIVE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">venv</span><span class="p">.</span><span class="n">tgz</span><span class="p">;</span>
<span class="k">ADD</span> <span class="n">ARCHIVE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">venv</span><span class="p">.</span><span class="n">tgz</span><span class="p">;</span>
<span class="k">DELETE</span> <span class="n">FILE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">udaf</span><span class="p">.</span><span class="n">py</span><span class="p">;</span>
<span class="k">ADD</span> <span class="n">FILE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">udaf</span><span class="p">.</span><span class="n">py</span><span class="p">;</span>
<span class="k">DELETE</span> <span class="n">FILE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">udaf</span><span class="p">.</span><span class="n">sh</span><span class="p">;</span>
<span class="k">ADD</span> <span class="n">FILE</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">tmp</span><span class="o">/</span><span class="n">udaf</span><span class="p">.</span><span class="n">sh</span><span class="p">;</span>

<span class="n">USE</span> <span class="n">tmp</span><span class="p">;</span>
<span class="k">SELECT</span> <span class="k">TRANSFORM</span><span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">price</span><span class="p">)</span> <span class="k">USING</span> <span class="s1">&#39;udaf.sh&#39;</span> <span class="k">AS</span> <span class="p">(</span><span class="n">vtype</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">mean</span> <span class="nb">FLOAT</span><span class="p">,</span> <span class="n">var</span> <span class="nb">FLOAT</span><span class="p">)</span>
  <span class="k">FROM</span> <span class="p">(</span><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">foo</span> <span class="k">CLUSTER</span> <span class="k">BY</span> <span class="n">vtype</span><span class="p">)</span> <span class="k">AS</span> <span class="n">TEMP_TABLE</span><span class="p">;</span>
</code></pre></div>

<p>At first we add the zipped virtual environment to the distributed cache that
will be automatically unpacked for us due to the <code>ADD ARCHIVE</code> command.
Then we upload the Python and helper script. To make sure the current version
in the cache is actually the latest, so in case changes are made, we
prepended <code>DELETE</code> statements before each <code>ADD</code>.</p>
<p>The actual query now calls <code>TRANSFORM</code> with the three input column we expect
in our Python script. After the <code>USING</code> statement our helper script is provided
as the actual <span class="caps">UDAF</span> seen by HiveQL. This is followed by <code>AS</code> defining the names
and types of the output&nbsp;columns.</p>
<p>At this point we need to make sure that the script is executed in a reducer step.
We assure this by defining a subselect that reads from our <code>foo</code> table and clusters
by the <code>vtype</code>. <code>CLUSTER BY</code> which is a shortcut for <code>DISTRIBUTE BY</code> followed by
<code>SORT BY</code> asserts that rows having the same <code>vtype</code> column are also located on
the same reducer. Furthermore, the implicit <code>SORT BY</code> orders within a reducer
the rows with respect to the <code>vtype</code> column. The overall result are consecutive
partitions of a given vehicle type (car and bike in our case) whereas each partition resides
on a single reducer. Finally, our script is fed the whole data on a single reducer
and needs to figure out itself where one partition ends and another one starts
(what we did with <code>itertools.groupby</code>).</p>
<h2>Finally</h2>
<p>Since our little task is now accomplished, it should also be noted that there
are some more Python libraries one should know when working with Hive.
To actually execute the HiveQL query we have written with the help of Python, there
is <a href="https://github.com/cloudera/impyla">impyla</a> by Cloudera with supports Python 3 in contrast to <a href="https://github.com/dropbox/PyHive">PyHive</a> by Dropbox.
In order to work with <span class="caps">HDFS</span> the best library around is <a href="https://hdfs3.readthedocs.io/">hdfs3</a>. That would
for instance allow us to push changes in <code>udaf.py</code> automatically with a Python&nbsp;script.</p>
<p>Have fun hacking Hive with the power of&nbsp;Python!</p>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="https://florianwilhelm.info/2019/04/more_efficient_udfs_with_pyspark/">More Efficient <span class="caps">UD</span>(A)Fs with&nbsp;PySpark</a></li>
        <li><a href="https://florianwilhelm.info/2018/07/how_mobilede_brings_ds_to_prod_for_a_personalized_web_experience/">How mobile.de brings Data Science to Production for a Personalized Web&nbsp;Experience</a></li>
        <li><a href="https://florianwilhelm.info/2017/10/efficient_udfs_with_pyspark/">Efficient <span class="caps">UD</span>(A)Fs with&nbsp;PySpark</a></li>
        <li><a href="https://florianwilhelm.info/2013/10/handling_big_data_with_python/">Handling Big Data with&nbsp;Python</a></li>
        <li><a href="https://florianwilhelm.info/2021/09/Handling_Anaconda_without_getting_constricted/">Handling Anaconda without getting&nbsp;Constricted</a></li>
    </ul>
</section>
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'florianwilhelmblog'; // required: replace example with your forum shortname

            var disqus_config = function () {
                this.language = "en";

                        this.page.identifier = '2016-10-23-python_udf_in_hive';
                        this.page.url = 'https://florianwilhelm.info/2016/10/python_udf_in_hive/';
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://twitter.com/FlorianWilhelm"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
    <li class="list-group-item"><a href="https://linkedin.com/in/florian-wilhelm-621ba834"><i class="fa fa-linkedin-square fa-lg"></i> LinkedIn</a></li>
    <li class="list-group-item"><a href="https://github.com/FlorianWilhelm"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="https://florianwilhelm.info/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/asynchronous/">asynchronous</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/asyncio/">asyncio</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/bayesian/">bayesian</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/big-data/">big data</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/bokeh/">bokeh</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/causal-inference/">causal inference</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://florianwilhelm.info/tag/data-science/">data science</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/deep-learning/">deep learning</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/event-driven/">event-driven</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/gans/">GANs</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/google-hangouts/">google hangouts</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/gps/">gps</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/hadoop/">hadoop</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/hive/">hive</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/jupyter/">jupyter</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/kalman-filter/">kalman filter</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/machine-learning/">machine-learning</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://florianwilhelm.info/tag/mathematics/">mathematics</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/nlp/">nlp</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://florianwilhelm.info/tag/predictive-analytics/">predictive analytics</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/production/">production</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/programming/">programming</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://florianwilhelm.info/tag/python/">Python</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/recommender-systems/">recommender systems</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/scikit-learn/">scikit-learn</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/scipy/">scipy</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/semi-supervised/">semi-supervised</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://florianwilhelm.info/tag/spark/">spark</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/template/">template</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://florianwilhelm.info/tag/uncertainty-quantification/">uncertainty quantification</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2021 Florian Wilhelm
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://florianwilhelm.info/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://florianwilhelm.info/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://florianwilhelm.info/theme/js/respond.min.js"></script>


    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'florianwilhelmblog'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-71694209-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->


<script>
   $(document).ready(function () {
      $("table").attr("class","table table-condensed table-bordered");
   });
</script>
</body>
</html>