<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Using Python packages with PySpark - Florian Wilhelm</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">




<style type="text/css">

/*some stuff for output/input prompts*/
div.cell{border:1px solid transparent;display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}div.cell.selected{border-radius:4px;border:thin #ababab solid}
div.cell.edit_mode{border-radius:4px;border:thin #008000 solid}
div.cell{width:100%;padding:5px 5px 5px 0;margin:0;outline:none}
div.prompt{min-width:11ex;padding:.4em;margin:0;font-family:monospace;text-align:right;line-height:1.21429em}
@media (max-width:480px){div.prompt{text-align:left}}div.inner_cell{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}
div.input_area{border:1px solid #cfcfcf;border-radius:4px;background:#f7f7f7;line-height:1.21429em}
div.prompt:empty{padding-top:0;padding-bottom:0}
div.input{page-break-inside:avoid;display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;}
div.inner_cell{width:90%;}
div.input_area{border:1px solid #cfcfcf;border-radius:4px;background:#f7f7f7;}
div.input_prompt{color:navy;border-top:1px solid transparent;}
div.output_wrapper{margin-top:5px;position:relative;display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;width:100%;}
div.output_scroll{height:24em;width:100%;overflow:auto;border-radius:4px;-webkit-box-shadow:inset 0 2px 8px rgba(0, 0, 0, 0.8);-moz-box-shadow:inset 0 2px 8px rgba(0, 0, 0, 0.8);box-shadow:inset 0 2px 8px rgba(0, 0, 0, 0.8);}
div.output_collapsed{margin:0px;padding:0px;display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;width:100%;}
div.out_prompt_overlay{height:100%;padding:0px 0.4em;position:absolute;border-radius:4px;}
div.out_prompt_overlay:hover{-webkit-box-shadow:inset 0 0 1px #000000;-moz-box-shadow:inset 0 0 1px #000000;box-shadow:inset 0 0 1px #000000;background:rgba(240, 240, 240, 0.5);}
div.output_prompt{color:darkred;}

a.anchor-link:link{text-decoration:none;padding:0px 20px;visibility:hidden;}
h1:hover .anchor-link,h2:hover .anchor-link,h3:hover .anchor-link,h4:hover .anchor-link,h5:hover .anchor-link,h6:hover .anchor-link{visibility:visible;}
/* end stuff for output/input prompts*/


.highlight-ipynb .hll { background-color: #ffffcc }
.highlight-ipynb  { background: #f8f8f8; }
.highlight-ipynb .c { color: #408080; font-style: italic } /* Comment */
.highlight-ipynb .err { border: 1px solid #FF0000 } /* Error */
.highlight-ipynb .k { color: #008000; font-weight: bold } /* Keyword */
.highlight-ipynb .o { color: #666666 } /* Operator */
.highlight-ipynb .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight-ipynb .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight-ipynb .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight-ipynb .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight-ipynb .gd { color: #A00000 } /* Generic.Deleted */
.highlight-ipynb .ge { font-style: italic } /* Generic.Emph */
.highlight-ipynb .gr { color: #FF0000 } /* Generic.Error */
.highlight-ipynb .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight-ipynb .gi { color: #00A000 } /* Generic.Inserted */
.highlight-ipynb .go { color: #888888 } /* Generic.Output */
.highlight-ipynb .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight-ipynb .gs { font-weight: bold } /* Generic.Strong */
.highlight-ipynb .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight-ipynb .gt { color: #0044DD } /* Generic.Traceback */
.highlight-ipynb .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight-ipynb .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight-ipynb .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight-ipynb .kp { color: #008000 } /* Keyword.Pseudo */
.highlight-ipynb .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight-ipynb .kt { color: #B00040 } /* Keyword.Type */
.highlight-ipynb .m { color: #666666 } /* Literal.Number */
.highlight-ipynb .s { color: #BA2121 } /* Literal.String */
.highlight-ipynb .na { color: #7D9029 } /* Name.Attribute */
.highlight-ipynb .nb { color: #008000 } /* Name.Builtin */
.highlight-ipynb .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight-ipynb .no { color: #880000 } /* Name.Constant */
.highlight-ipynb .nd { color: #AA22FF } /* Name.Decorator */
.highlight-ipynb .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight-ipynb .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight-ipynb .nf { color: #0000FF } /* Name.Function */
.highlight-ipynb .nl { color: #A0A000 } /* Name.Label */
.highlight-ipynb .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight-ipynb .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight-ipynb .nv { color: #19177C } /* Name.Variable */
.highlight-ipynb .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight-ipynb .w { color: #bbbbbb } /* Text.Whitespace */
.highlight-ipynb .mf { color: #666666 } /* Literal.Number.Float */
.highlight-ipynb .mh { color: #666666 } /* Literal.Number.Hex */
.highlight-ipynb .mi { color: #666666 } /* Literal.Number.Integer */
.highlight-ipynb .mo { color: #666666 } /* Literal.Number.Oct */
.highlight-ipynb .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight-ipynb .sc { color: #BA2121 } /* Literal.String.Char */
.highlight-ipynb .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight-ipynb .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight-ipynb .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight-ipynb .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight-ipynb .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight-ipynb .sx { color: #008000 } /* Literal.String.Other */
.highlight-ipynb .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight-ipynb .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight-ipynb .ss { color: #19177C } /* Literal.String.Symbol */
.highlight-ipynb .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight-ipynb .vc { color: #19177C } /* Name.Variable.Class */
.highlight-ipynb .vg { color: #19177C } /* Name.Variable.Global */
.highlight-ipynb .vi { color: #19177C } /* Name.Variable.Instance */
.highlight-ipynb .il { color: #666666 } /* Literal.Number.Integer.Long */
</style>

<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
div.entry-content {
  overflow: visible;
  padding: 8px;
}
.input_area {
  padding: 0.2em;
}

a.heading-anchor {
 white-space: normal;
}

.rendered_html
code {
 font-size: .8em;
}

pre.ipynb {
  color: black;
  background: #f7f7f7;
  border: none;
  box-shadow: none;
  margin-bottom: 0;
  padding: 0;
  margin: 0px;
  font-size: 13px;
}

/* remove the prompt div from text cells */
div.text_cell .prompt {
    display: none;
}

/* remove horizontal padding from text cells, */
/* so it aligns with outer body text */
div.text_cell_render {
    padding: 0.5em 0em;
}

img.anim_icon{padding:0; border:0; vertical-align:middle; -webkit-box-shadow:none; -box-shadow:none}
</style>

<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<script type="text/javascript">
init_mathjax = function() {
    if (window.MathJax) {
        // MathJax loaded
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            },
            displayAlign: 'left', // Change this to 'center' to center equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    }
}
init_mathjax();
</script>

<link rel="canonical" href="http://www.florianwilhelm.info/drafts/practical_pyspark_in_production.html">

        <meta name="author" content="Florian Wilhelm" />
        <meta name="keywords" content="spark,python" />
        <meta name="description" content="With the sustained success of the Spark data processing platform even data scientists with a strong focus on the Python ecosystem can no longer ignore it. Fortunately with PySpark, official Python support for Spark is available and easy to use with millions of tutorials on the web explaining you how …" />

        <meta property="og:site_name" content="Florian Wilhelm" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Using Python packages with PySpark"/>
        <meta property="og:url" content="http://www.florianwilhelm.info/drafts/practical_pyspark_in_production.html"/>
        <meta property="og:description" content="With the sustained success of the Spark data processing platform even data scientists with a strong focus on the Python ecosystem can no longer ignore it. Fortunately with PySpark, official Python support for Spark is available and easy to use with millions of tutorials on the web explaining you how …"/>
        <meta property="article:published_time" content="2017-06-01" />
            <meta property="article:section" content="article" />
            <meta property="article:tag" content="spark" />
            <meta property="article:tag" content="python" />
            <meta property="article:author" content="Florian Wilhelm" />

    <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@FlorianWilhelm">
        <meta name="twitter:creator" content="@FlorianWilhelm">
    <meta name="twitter:domain" content="http://www.florianwilhelm.info">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="http://www.florianwilhelm.info/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="http://www.florianwilhelm.info/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="http://www.florianwilhelm.info/theme/css/pygments/native.css" rel="stylesheet">
        <link href="http://www.florianwilhelm.info/theme/css/typogrify.css" rel="stylesheet">
    <link rel="stylesheet" href="http://www.florianwilhelm.info/theme/css/style.css" type="text/css"/>




        <link href="http://www.florianwilhelm.info/feeds/article.atom.xml" type="application/atom+xml" rel="alternate"
              title="Florian Wilhelm article ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="http://www.florianwilhelm.info/" class="navbar-brand">
Florian Wilhelm            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/">Home</a></li>
                    <li><a href="/about/">About me</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><a href="http://www.florianwilhelm.info/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="http://www.florianwilhelm.info/drafts/practical_pyspark_in_production.html"
                       rel="bookmark"
                       title="Permalink to Using Python packages with PySpark">
                        Using Python packages with&nbsp;PySpark
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-06-01T12:30:00+02:00"> Jun. 01, 2017</time>
    </span>


            <span class="label label-default">By</span>
            <a href="http://www.florianwilhelm.info/author/florian-wilhelm.html"><i class="fa fa-user"></i> Florian Wilhelm</a>



<span class="label label-default">Tags</span>
	<a href="http://www.florianwilhelm.info/tag/spark/">spark</a>
        /
	<a href="http://www.florianwilhelm.info/tag/python/">python</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>With the sustained success of the Spark data processing platform even data scientists with a strong focus on the Python ecosystem can no longer ignore it. Fortunately with PySpark, official Python support for Spark is available and easy to use with millions of tutorials on the web explaining you how to count words. In contrast to that I found resources on how to deploy and use Python packages like Numpy, Pandas, Scikit-Learn in a PySpark program quite lacking. For most Spark/Hadoop distributions, in my case Cloudera, the best-practise arroding to Cloudera&#8217;s <a href="https://www.cloudera.com/documentation/enterprise/5-6-x/topics/spark_python.html#spark_python__section_kr2_4zs_b5">documentation</a> and <a href="http://blog.cloudera.com/blog/2016/02/making-python-on-apache-hadoop-easier-with-anaconda-and-cdh/">blog</a> seems to be that you (or rather a sysadmin) sets up a dedicated virtual environment (with <a href="https://virtualenv.pypa.io/en/stable/">virtualenv</a> or <a href="https://conda.io/docs/intro.html">conda</a>) on all hosts of your cluster. This virtual environment can then be used by your PySpark application. The drawback of this approach are as severe as obvious. Firstly, either your data scientists have permission to access the actual cluster hosts or Cloudera Manager Admin Console with all implications or your sysadmins have a lot of fun setting up hundreds of virtual environments on a daily basis. Secondly, we are introducing a state in your Spark jobs which is always a root cause of errors in&nbsp;production:</p>
<p><strong>DataScientist</strong>: &#8220;I deployed my virtual envs on all hosts two weeks ago, now my production code fails occasionally with missing imports.&#8221;<br />
 <strong>SysAdmin</strong>: &#8220;Well, we added a few more nodes a week ago&#8230; did you push your envs to&nbsp;those?&#8221;</p>
<p>In order to prevent situations like this we want to deploy our application with all its dependencies bundled every time we run it, just like you would to with a jar file in Scala. Since Python is not a compiled language this task sounds easier than it actually is. This observation is recognized as a problem and several issues (<a href="https://issues.apache.org/jira/browse/SPARK-13587"><span class="caps">SPARK</span>-13587</a> <span class="amp">&amp;</span> <a href="https://issues.apache.org/jira/browse/SPARK-16367"><span class="caps">SPARK</span>-16367</a>) suggest solutions but none are implemented yet. So we are coming to the point were things get interesting and our goal is set. Coming up with a solution that allows bundling all requirements together with the actual PySpark application and of course it should not be too hacky&nbsp;;-)</p>
<p>Luckily, PySpark provides the functions <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext.addFile">sc.addFile</a> and <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext.addPyFile">sc.addPyFile</a> which allow us uploading files to every node in our cluster, even Python modules and egg files in case of the latter. Unfortunately, there is no way to upload wheel files which are needed for binary Python packages like Numpy, Pandas and so on. As a data scientist you cannot live without those. At first sight this looks pretty bad but thanks to the wheel format all we have to do is upload with <code>sc.addFile</code> and unpack them, even the <code>PYTHONPATH</code> will be correctly set for us by PySpark. So in theory, we have already all the tools we need but how do we get the proper wheel files? First we check the Python version we want to use on Spark, in my case that is Python 3.4 on Cloudera cdh5.11.0. Now on some Linux, which needs to be compatible with the Linux on your Spark distribution, we create an Anaconda environment with the exact same Python&nbsp;version:</p>
<div class="highlight"><pre><span></span>conda create -n py34 <span class="nv">python</span><span class="o">=</span><span class="m">3</span>.4
<span class="nb">source</span> activate py34
</pre></div>


<p>Having activated the environment, we just use <code>pip download</code> to download all the requirements of our PySpark application as well as the requirements of the requirements and so on. In case there is no wheel file available, <code>pip</code> will download a source-based <code>tar.gz</code> file instead but we can easily generate a wheel from it. To do so, we just unpack the archive, change into the directory and type <code>python setup.py bdist_wheel</code>. A wheel file should now reside in the <code>dist</code> folder. Thereafter, we push all wheel files into some hdfs directory that is accessible by spark. For this example we will use <code>hdfs:///absolute/path/to/wheelhouse</code>. At this point one should also be aware that some wheel files come with low-level Linux dependencies that just need to be installed by a sysadmin on every host, e.g. <code>python3-dev</code> and <code>unixodbc-dev</code>.   </p>
<p>Up until now was only preliminary skirmishing, so let&#8217;s get coding Python. We stick to the plan we laid out before, all we need to do is adding the files from our hdfs directory to the Spark context. Then, we unzip the files since wheel files are just plain zip files with a special structure and some meta information and that&#8217;s about it. The code below will demonstrate this and often serves me as a basic template for a typical PySpark script. Therefore, the template also generates a <code>SparkSession</code> with Hive support, fires a query and converts it into a Pandas dataframe which can be removed of course if not needed. To execute the code just name it <code>pyspark_with_py_pgks.py</code> and run it with a command similar to this&nbsp;one:</p>
<div class="highlight"><pre><span></span><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>python3.4 /opt/spark/bin/spark-submit --master yarn --deploy-mode cluster <span class="se">\</span>
--num-executors <span class="m">4</span> --driver-memory 12g --executor-memory 4g --executor-cores <span class="m">1</span> <span class="se">\</span>
--files /etc/spark/conf/hive-site.xml --queue default --conf spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">1</span> <span class="se">\</span>
pyspark_with_py_pgks.py
</pre></div>


<p>The code is pretty much self-explanatory. If not, just drop me a line in the comments&nbsp;below:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">zipfile</span> <span class="kn">import</span> <span class="n">ZipFile</span>

<span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkFiles</span>


<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">add_pkg</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">addFile</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">root_dir</span> <span class="o">=</span> <span class="n">SparkFiles</span><span class="o">.</span><span class="n">getRootDirectory</span><span class="p">()</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_file</span><span class="p">:</span>
        <span class="n">zip_file</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">root_dir</span><span class="p">)</span>
    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added package {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file_name</span><span class="p">))</span>    


<span class="n">sess</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span>
         <span class="o">.</span><span class="n">builder</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Python Spark Data Science Stack Check&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>
         <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>

<span class="c1"># setup basic logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>

<span class="c1"># upload all dependencies</span>
<span class="n">wheelhouse</span> <span class="o">=</span> <span class="s1">&#39;hdfs:///absolute/path/to/wheelhouse&#39;</span>
<span class="n">pkgs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;turbodbc-1.1.1-cp34-cp34m-linux_x86_64.whl&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;numpy-1.12.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;six-1.10.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Jinja2-2.9.6-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;MarkupSafe-1.0-cp34-cp34m-linux_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;cycler-0.10.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pandas-0.20.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pybind11-2.1.1-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pyparsing-2.2.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;python_dateutil-2.6.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pytz-2017.2-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;scikit_learn-0.18.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;scipy-0.19.0-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="n">pkgs</span><span class="p">:</span>
    <span class="n">add_pkg</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">wheelhouse</span><span class="p">,</span> <span class="n">pkg</span><span class="p">))</span>

<span class="c1"># do the actual importing after adding the package</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="kn">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">sklearn</span>

<span class="c1"># just some random query </span>
<span class="n">spark_df</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM my_database.my_table LIMIT 10&quot;</span><span class="p">)</span>
<span class="n">pd_df</span> <span class="o">=</span> <span class="n">spark_df</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">pd_df</span><span class="p">)</span>

<span class="c1"># print some versions to check with above</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Python&#39;</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;PySpark&#39;</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;NumPy&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;SciPy&#39;</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Pandas&#39;</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Scikit-Learn&#39;</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1"># check that NumPy really works ;-)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>


<p>Das hier noch verwerten
http://blog.cloudera.com/blog/2015/09/how-to-prepare-your-apache-hadoop-cluster-for-pyspark-jobs/&nbsp;https://stackoverflow.com/questions/37343437/how-to-run-a-function-on-all-spark-workers-before-processing-data-in-pyspark</p>
<p>sc._jsc.sc().getExecutorMemoryStatus().size()
&#8216;-&#8216;.join(a.split(&#8216;-&#8216;)[:2]) +&nbsp;&#8220;.dist-info&#8221;</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">zipfile</span> <span class="kn">import</span> <span class="n">ZipFile</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>

<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkFiles</span>
<span class="kn">from</span> <span class="nn">pyspark.context</span> <span class="kn">import</span> <span class="n">SparkContext</span>


<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PyEnv</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wheelhouse</span><span class="p">,</span> <span class="n">pkgs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wheelhouse</span> <span class="o">=</span> <span class="n">wheelhouse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pkgs</span> <span class="o">=</span> <span class="n">pkgs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pkgs</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wheelhouse</span><span class="p">,</span> <span class="n">pkg</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_pkg</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unpack_pkg</span><span class="p">(</span><span class="n">pkg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">add_pkg</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">SparkContext</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span><span class="o">.</span><span class="n">addFile</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added file {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">unpack_pkg</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pkg</span><span class="p">):</span>
        <span class="n">root_dir</span> <span class="o">=</span> <span class="n">SparkFiles</span><span class="o">.</span><span class="n">getRootDirectory</span><span class="p">()</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">pkg</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_file</span><span class="p">:</span>
            <span class="n">zip_file</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">root_dir</span><span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Extracted package {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pkg</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">,</span> <span class="s2">&quot;You need to run .init() first&quot;</span>

        <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pkgs</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">unpack_pkg</span><span class="p">(</span><span class="n">pkg</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">wrapper</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span><span class="p">,</span> <span class="n">collect_list</span><span class="p">,</span> <span class="n">isnull</span><span class="p">,</span> <span class="n">struct</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">LongType</span><span class="p">,</span> <span class="n">FloatType</span><span class="p">,</span> <span class="n">MapType</span><span class="p">,</span> <span class="n">StringType</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkFiles</span>

<span class="kn">from</span> <span class="nn">pyenv</span> <span class="kn">import</span> <span class="n">PyEnv</span>

<span class="n">sess</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span>
         <span class="o">.</span><span class="n">builder</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Python Spark SQL Hive integration example&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>
         <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># setup basic logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>

<span class="n">wheelhouse</span> <span class="o">=</span> <span class="s1">&#39;hdfs:///company/MOBILE/data-platform/wheelhouse/&#39;</span>
<span class="n">pkgs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;turbodbc-1.1.1-cp34-cp34m-linux_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;numpy-1.12.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;six-1.10.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Jinja2-2.9.6-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;MarkupSafe-1.0-cp34-cp34m-linux_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;cycler-0.10.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pandas-0.20.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pybind11-2.1.1-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pyparsing-2.2.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;python_dateutil-2.6.0-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pytz-2017.2-py2.py3-none-any.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;scikit_learn-0.18.1-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">,</span>
        <span class="s1">&#39;scipy-0.19.0-cp34-cp34m-manylinux1_x86_64.whl&#39;</span><span class="p">]</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">PyEnv</span><span class="p">(</span><span class="n">wheelhouse</span><span class="p">,</span> <span class="n">pkgs</span><span class="p">)</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># do the actual importing after adding the package</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="kn">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">turbodbc</span>

<span class="nd">@env</span>
<span class="k">def</span> <span class="nf">squared</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
    <span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">rnd</span>


<span class="nd">@env</span>
<span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="n">struct</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
    <span class="n">series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">elem</span><span class="o">.</span><span class="n">fuel</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">struct</span><span class="p">])</span>    
    <span class="n">dct</span> <span class="o">=</span>  <span class="n">series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dct</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>


<span class="n">squared_udf</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="n">squared</span><span class="p">,</span> <span class="n">FloatType</span><span class="p">())</span>
<span class="n">count_udf</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">MapType</span><span class="p">(</span><span class="n">StringType</span><span class="p">(),</span> <span class="n">LongType</span><span class="p">()))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;user_profiles_prod.monitor_profiles&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;sub_count&quot;</span><span class="p">,</span> <span class="n">squared_udf</span><span class="p">(</span><span class="s2">&quot;sub_count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;sub_count_squared&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;fwilhelm.profile_test&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;uid&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">collect_list</span><span class="p">(</span><span class="n">struct</span><span class="p">(</span><span class="s1">&#39;fuel&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;struct&#39;</span><span class="p">))</span>
        <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">count_udf</span><span class="p">(</span><span class="s1">&#39;struct&#39;</span><span class="p">)))</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">pd_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">pd_df</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;PySpark&#39;</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Numpy&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Pandas&#39;</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Scikit-Learn&#39;</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;turbodbc&#39;</span><span class="p">,</span> <span class="n">turbodbc</span><span class="o">.</span><span class="n">api_constants</span><span class="o">.</span><span class="n">apilevel</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;SciPy&#39;</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1"># check that numpy really works ;-)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>python3.4 /opt/spark/bin/spark-submit --master yarn --deploy-mode cluster --num-executors <span class="m">4</span> --driver-memory 12g --executor-memory 4g --executor-cores <span class="m">2</span> --files /etc/spark/conf/hive-site.xml --queue default --conf spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">1</span> --py-files pyenv.py test.py
</pre></div>


<p>ToDo:
- erwaehnen wie man die replication auf der venv erhoeht.
- unterschied driver und executor&nbsp;erwaehnen</p>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="http://www.florianwilhelm.info/2017/10/efficient_udfs_with_pyspark/">Efficient <span class="caps">UD</span>(A)Fs with&nbsp;PySpark</a></li>
        <li><a href="http://www.florianwilhelm.info/2017/07/declarative_thinking_and_programming/">Declarative Thinking and&nbsp;Programming</a></li>
        <li><a href="http://www.florianwilhelm.info/2017/04/causal_inference_propensity_score/">Causal Inference and Propensity Score&nbsp;Methods</a></li>
        <li><a href="http://www.florianwilhelm.info/2016/10/python_udf_in_hive/">Hive UDFs and UDAFs with&nbsp;Python</a></li>
        <li><a href="http://www.florianwilhelm.info/2016/07/handling_gps_data_with_python/">Handling <span class="caps">GPS</span> Data with&nbsp;Python</a></li>
    </ul>
</section>
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'florianwilhelmblog'; // required: replace example with your forum shortname

                    var disqus_identifier = 'practical_pyspark_in_production';
                var disqus_url = 'http://www.florianwilhelm.info/drafts/practical_pyspark_in_production.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>

<section class="well well-sm">
    <ul class="list-group list-group-flush">
        <li class="list-group-item"><h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
              <ul class="list-group" id="social">
                <li class="list-group-item"><a href="https://twitter.com/FlorianWilhelm"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
                <li class="list-group-item"><a href="https://linkedin.com/in/florian-wilhelm-621ba834"><i class="fa fa-linkedin-square fa-lg"></i> LinkedIn</a></li>
                <li class="list-group-item"><a href="https://github.com/FlorianWilhelm"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
              </ul>
            </li>



            <li class="list-group-item"><a href="http://www.florianwilhelm.info/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
                <ul class="list-group list-inline tagcloud" id="tags">
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/asynchronous/">
                            asynchronous
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/asyncio/">
                            asyncio
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/bayesian/">
                            bayesian
                        </a>
                    </li>
                    <li class="list-group-item tag-2">
                        <a href="http://www.florianwilhelm.info/tag/big-data/">
                            big data
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/blue-yonder/">
                            Blue Yonder
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/bokeh/">
                            bokeh
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/causal-inference/">
                            causal inference
                        </a>
                    </li>
                    <li class="list-group-item tag-3">
                        <a href="http://www.florianwilhelm.info/tag/data-science/">
                            data science
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/event-driven/">
                            event-driven
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/google-hangouts/">
                            google hangouts
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/gps/">
                            gps
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/hadoop/">
                            hadoop
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/hive/">
                            hive
                        </a>
                    </li>
                    <li class="list-group-item tag-2">
                        <a href="http://www.florianwilhelm.info/tag/jupyter/">
                            jupyter
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/kalman/">
                            kalman
                        </a>
                    </li>
                    <li class="list-group-item tag-2">
                        <a href="http://www.florianwilhelm.info/tag/machine-learning/">
                            machine-learning
                        </a>
                    </li>
                    <li class="list-group-item tag-3">
                        <a href="http://www.florianwilhelm.info/tag/predictive-analytics/">
                            predictive analytics
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/programming/">
                            programming
                        </a>
                    </li>
                    <li class="list-group-item tag-1">
                        <a href="http://www.florianwilhelm.info/tag/python/">
                            python
                        </a>
                    </li>
                    <li class="list-group-item tag-2">
                        <a href="http://www.florianwilhelm.info/tag/scikit-learn/">
                            scikit-learn
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/scipy/">
                            scipy
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/spark/">
                            spark
                        </a>
                    </li>
                    <li class="list-group-item tag-4">
                        <a href="http://www.florianwilhelm.info/tag/template/">
                            template
                        </a>
                    </li>
                </ul>
            </li>


    </ul>
</section>            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Florian Wilhelm
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://www.florianwilhelm.info/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="http://www.florianwilhelm.info/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="http://www.florianwilhelm.info/theme/js/respond.min.js"></script>

    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'florianwilhelmblog'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-71694209-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->

</body>
</html>