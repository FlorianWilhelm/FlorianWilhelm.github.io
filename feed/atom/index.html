<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Florian Wilhelm's blog</title><link href="https://florianwilhelm.info/" rel="alternate"></link><link href="https://florianwilhelm.info/feed/atom/index.html" rel="self"></link><id>https://florianwilhelm.info/</id><updated>2022-10-16T08:00:00+02:00</updated><entry><title>Forget about AI and do Mathematical Modelling instead!</title><link href="https://florianwilhelm.info/2022/10/forget_about_ai_and_do_mathematical_modelling_instead/" rel="alternate"></link><published>2022-10-16T08:00:00+02:00</published><updated>2022-10-16T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2022-10-16:/2022/10/forget_about_ai_and_do_mathematical_modelling_instead/</id><summary type="html">&lt;p&gt;The term artificial intelligence (&lt;span class="caps"&gt;AI&lt;/span&gt;) seems to be ubiquitous these days. It seems that anything can and should be solved using &lt;span class="caps"&gt;AI&lt;/span&gt; but does it really make sense to use neural networks for every&amp;nbsp;use-case?&lt;/p&gt;</summary><content type="html">&lt;p&gt;The term artificial intelligence (&lt;span class="caps"&gt;AI&lt;/span&gt;) seems to be ubiquitous these days. It is being used or is supposed to be used, in almost all areas to automate processes, perform difficult tasks or to help us make decisions.
In my talk presented at &lt;a href="https://codetalks.de/program#talk-1118?event=7"&gt;Code.Talks 2022&lt;/a&gt;, I invite you to take a look behind the hype around &lt;span class="caps"&gt;AI&lt;/span&gt; and show you from my practical experiences as a data scientist that many relevant use-cases can be solved without it,
just by applying some old-school &lt;em&gt;mathematical modelling&lt;/em&gt;. You will see the advantages of mathematical modelling, like interpretability, data-efficiency, robustness, etc. over 
&lt;span class="caps"&gt;AI&lt;/span&gt; based approaches. The main take-away is that you should always focus on understanding the problem itself before you choose a method - be it a neural network or linear regression - to solve&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;The slides are available on &lt;a href="https://www.slideshare.net/FlorianWilhelm2/forget-about-ai-and-do-mathematical-modelling-instead"&gt;SlideShare&lt;/a&gt; and a podcast episode about the same topic is available on &lt;a href="https://digital-future.podigee.io/13-neue-episode#t=2"&gt;Digital Future&lt;/a&gt;, the &lt;a href="https://www.inovex.de/en/"&gt;inovex&lt;/a&gt; podcast, in&amp;nbsp;German.&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/S_vefzluy4o'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="data science"></category><category term="mathematics"></category><category term="ai"></category></entry><entry><title>Effective and Consistent Configuration via YAML &amp; CLI with Hydra</title><link href="https://florianwilhelm.info/2022/01/configuration_via_yaml_and_cli_with_hydra/" rel="alternate"></link><published>2022-01-27T10:00:00+01:00</published><updated>2022-01-27T10:00:00+01:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2022-01-27:/2022/01/configuration_via_yaml_and_cli_with_hydra/</id><summary type="html">&lt;p&gt;Hydra allows you to have consistent configuration of Python applications via a command-line interface and &lt;span class="caps"&gt;YAML&lt;/span&gt;&amp;nbsp;files.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A frequent requirement for productive Python application is that they are configurable via configuration files and/or
the command-line-interface (&lt;span class="caps"&gt;CLI&lt;/span&gt;). This allows you to change the behavior of your application without touching the source code, e.g. configuring
another database &lt;span class="caps"&gt;URL&lt;/span&gt; or the logging verbosity. For the &lt;span class="caps"&gt;CLI&lt;/span&gt;-part, &lt;a href="https://docs.python.org/3/library/argparse.html"&gt;argparse&lt;/a&gt; or &lt;a href="https://click.palletsprojects.com/"&gt;click&lt;/a&gt; is often used and with &lt;a href="https://pyyaml.org/"&gt;PyYAML&lt;/a&gt; configuration files
can be easily read, so where is the&amp;nbsp;problem?&lt;/p&gt;
&lt;p&gt;Configuration of a Python application by &lt;span class="caps"&gt;CLI&lt;/span&gt; or a &lt;span class="caps"&gt;YAML&lt;/span&gt; file have many things in common, i.e.,&amp;nbsp;both&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;configure the runtime behaviour of your&amp;nbsp;application,&lt;/li&gt;
&lt;li&gt;need to implement validations, e.g. is the port an integer above&amp;nbsp;1024,&lt;/li&gt;
&lt;li&gt;need to be consistent and mergeable, i.e. a &lt;span class="caps"&gt;CLI&lt;/span&gt; flag should be named like the &lt;span class="caps"&gt;YAML&lt;/span&gt; key and if both are passed the &lt;span class="caps"&gt;CLI&lt;/span&gt;
   overwrites the &lt;span class="caps"&gt;YAML&lt;/span&gt;&amp;nbsp;configuration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thus implementing configuration by a &lt;span class="caps"&gt;CLI&lt;/span&gt; and a &lt;span class="caps"&gt;YAML&lt;/span&gt; file separately, leads often to code duplication
and inconsistent behavior, not to mention the enormous amount of work that must be done to get this&amp;nbsp;right.&lt;/p&gt;
&lt;p&gt;With this in mind, Facebook implemented the &lt;a href="https://hydra.cc/"&gt;Hydra&lt;/a&gt; library, which allows you to do hierarchical configuration by
composition of config files and overrides via the command line. In this blog post, we demonstrate in an example project
the most important features of &lt;a href="https://hydra.cc/"&gt;Hydra&lt;/a&gt; and how it can be used in conjunction with &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt;,
which extends its validation capabilities. To follow along, check out  this &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project"&gt;repository&lt;/a&gt; that serves as a demonstration, but also as a playground for&amp;nbsp;you.&lt;/p&gt;
&lt;h3&gt;Ok, so give me the gist of how Hydra&amp;nbsp;works&lt;/h3&gt;
&lt;p&gt;Sure, just take a look into &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project/blob/master/src/my_pkg/cli.py"&gt;cli.py&lt;/a&gt; and &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project/blob/master/src/my_pkg/config.py"&gt;config.py&lt;/a&gt; first as these are the only files we added,
roughly 70 lines of code. The hierarchical configuration can be found in the &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project/tree/master/configs"&gt;configs&lt;/a&gt; folder and look like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;├── configs
│   ├── main.yaml             &amp;lt;- entry point for configuration
│   ├── db                    &amp;lt;- database configuration group
│   │   ├── mysql.yaml        &amp;lt;- configuration for MySQL
│   │   └── postgresql.yaml   &amp;lt;- configuration for PostgreSQL
│   └── experiment            &amp;lt;- experiment configuration group
│       ├── exp1.yaml         &amp;lt;- configuration for experiment 1
│       ├── exp2.yaml         &amp;lt;- configuration for experiment 2
│       ├── missing_key.yaml  &amp;lt;- wrong configuration with missing key
│       └── wrong_type.yaml   &amp;lt;- wrong configuration with wrong type
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Basically, this structure allows you to mix and match your configuration by choosing for instance the configuration for
the MySQL database with the configuration for experiment 2. Hydra creates for you one consistent configuration object,
some kind of nested dictionary of dictionaries, where each configuration group is an&amp;nbsp;attribute.&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project"&gt;repository&lt;/a&gt; of our example project, we defined the &lt;span class="caps"&gt;CLI&lt;/span&gt; command &lt;code&gt;hydra-test&lt;/code&gt; by changing in &lt;code&gt;setup.cfg&lt;/code&gt; the following&amp;nbsp;lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Add here console scripts like:&lt;/span&gt;
&lt;span class="na"&gt;console_scripts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
     &lt;span class="na"&gt;hydra-test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;my_pkg.cli:main&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can thus invoke our application with the console command &lt;code&gt;hydra-test&lt;/code&gt; and this will execute the &lt;code&gt;main&lt;/code&gt; function in &lt;code&gt;cli.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@hydra&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config_path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# this line actually runs the checks of pydantic&lt;/span&gt;
    &lt;span class="n"&gt;OmegaConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# log to console and into the `outputs` folder per default&lt;/span&gt;
    &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;OmegaConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_yaml&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# note that IDEs allow auto-complete for accessing the attributes!&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Looking at the actual code, we see that we only trigger some &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt; checks to see if the configuration and &lt;span class="caps"&gt;CLI&lt;/span&gt; parameters are correct,
then we log the current configuration and sleep for the time defined in the&amp;nbsp;configuration.&lt;/p&gt;
&lt;p&gt;So executing just &lt;code&gt;hydra-test&lt;/code&gt; results&amp;nbsp;in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Cannot find primary config &amp;#39;main&amp;#39;. Check that it&amp;#39;s in your config search path.

Config search path:
    provider=hydra, path=pkg://hydra.conf
    provider=main, path=pkg://my_pkg
    provider=schema, path=structured://

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is due to the fact that we set &lt;code&gt;config_path=None&lt;/code&gt;, which is desirable for a productive application. The application
itself doesn&amp;#8217;t know where it is going to be installed and thus defining a path to the configuration files doesn&amp;#8217;t make any sense.
For this reason we pass the configuration at execution time with &lt;code&gt;-cd&lt;/code&gt;, short form of &lt;code&gt;--config-dir&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;hydra-test -cd configs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This results in the&amp;nbsp;error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Error executing job with overrides: []
Traceback (most recent call last):
  File &amp;quot;.../hydra-example-project/src/my_pkg/cli.py&amp;quot;, line 11, in main
    OmegaConf.to_object(cfg)
omegaconf.errors.MissingMandatoryValue: Structured config of type `Config` has missing mandatory value: experiment
    full_key: experiment
    object_type=Config

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This behavior is exactly as we want it, because a look into &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project/blob/master/src/my_pkg/config.py"&gt;config.py&lt;/a&gt; shows us that the schema of the main configuration&amp;nbsp;is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Main&lt;/span&gt;
    &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DataBase&lt;/span&gt;
    &lt;span class="n"&gt;neptune&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Neptune&lt;/span&gt;
    &lt;span class="n"&gt;experiment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Experiment&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MISSING&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and the experiment is defined as &lt;code&gt;MISSING&lt;/code&gt;. Therefore, experiment is a mandatory parameter that the user needs to provide via the &lt;span class="caps"&gt;CLI&lt;/span&gt;. 
Consequently, we add &lt;code&gt;+experiment=exp1&lt;/code&gt; to select the configuration from &lt;code&gt;exp1.yaml&lt;/code&gt; and finally get what we would&amp;nbsp;expect:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯ hydra-test -cd configs +experiment=exp1
[2022-01-27 08:14:34,257][my_pkg.cli][INFO] -
main:
  sleep: 3
neptune:
  project: florian.wilhelm/my_expriments
  api_token: ~/.neptune_api_token
  tags:
  - run-1
  description: Experiment run on GCP
  mode: async
db:
  driver: mysql
  host: server_string
  port: ${oc.env:MYSQL_PORT,1028}
  username: myself
  password: secret
experiment:
  model: XGBoost
  l2: 0.01
  n_steps: 1000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note the plus sign in the flag &lt;code&gt;+experiment&lt;/code&gt;. This is needed since we &lt;em&gt;add&lt;/em&gt; the mandatory experiment parameter. Conveniently, 
Hydra has also set up the logging for us and besides logging to the terminal, all output will also be collected in the &lt;code&gt;./outputs&lt;/code&gt;
folder.&lt;/p&gt;
&lt;p&gt;So the section &lt;code&gt;main&lt;/code&gt; and &lt;code&gt;neptune&lt;/code&gt; are directly defined in &lt;code&gt;main.yaml&lt;/code&gt;, but why did Hydra now choose the MySQL database?
This is due to fact that in &lt;code&gt;main.yaml&lt;/code&gt;, we defined some&amp;nbsp;defaults:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# hydra section to build up the config hierarchy with defaults&lt;/span&gt;
&lt;span class="nt"&gt;defaults&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;_self_&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;base_config&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;mysql.yaml&lt;/span&gt;
  &lt;span class="c1"&gt;# experiment: is not mentioned here but in config.py to have a mandatory setting&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Taking a look into &lt;a href="https://github.com/FlorianWilhelm/hydra-example-project/blob/master/configs/db/mysql.yaml"&gt;mysql.yaml&lt;/a&gt;, we see that Hydra also allows accessing environment variables easily to help with 
configuration. As an example, we defined the database port to be whatever the environment variable &lt;code&gt;MYSQL_PORT&lt;/code&gt; is set
to or 1028 if undefined. So Hydra does not only unify the configuration via &lt;span class="caps"&gt;YAML&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; but also via environment&amp;nbsp;variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;driver&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;mysql&lt;/span&gt;
&lt;span class="nt"&gt;host&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;server_string&lt;/span&gt;
&lt;span class="nt"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;${oc.env:MYSQL_PORT,1028}&lt;/span&gt;
&lt;span class="nt"&gt;username&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;myself&lt;/span&gt;
&lt;span class="nt"&gt;password&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;secret&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can also override the default database by adding the flag &lt;code&gt;db=postgresql&lt;/code&gt;. This time the flag has no &lt;code&gt;+&lt;/code&gt; as we override a&amp;nbsp;default:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯ hydra-test -cd configs +experiment=exp1 db=postgresql
Error executing job with overrides: [&amp;#39;+experiment=exp1&amp;#39;, &amp;#39;db=postgresql&amp;#39;]
Traceback (most recent call last):
  File &amp;quot;.../hydra-example-project/src/my_pkg/cli.py&amp;quot;, line 11, in main
    OmegaConf.to_object(cfg)
pydantic.error_wrappers.ValidationError: 1 validation error for DataBase
port
  Choose a non-privileged port! (type=value_error)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Nice! This works just as expected by telling us that our port configuration is actually wrong as we chose a privileged port!
This is the magic of &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt; doing its validation work. Taking a look into &lt;code&gt;config.py&lt;/code&gt;, we see the check that assures
a port not smaller than&amp;nbsp;1024.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DataBase&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;driver&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="nd"&gt;@validator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;port&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_non_privileged_port&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;cls&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Choose a non-privileged port!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;
    &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;
    &lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Good, we can now fix our configuration file or just pass an extra parameter if we are in a hurry,&amp;nbsp;i.e.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯ hydra-test -cd configs +experiment=exp1 db=postgresql db.port=1832
[2022-01-27 08:13:52,148][my_pkg.cli][INFO] -
main:
  sleep: 3
neptune:
  project: florian.wilhelm/my_expriments
  api_token: ~/.neptune_api_token
  tags:
  - run-1
  description: Experiment run on GCP
  mode: async
db:
  driver: postgreqsql
  host: server_string
  port: 1832
  username: me
  password: birthday
experiment:
  model: XGBoost
  l2: 0.01
  n_steps: 1000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And this works! So much flexibility and robustness in just 70 lines of code, awesome! While you are at it, you can also
run &lt;code&gt;hydra-test -cd configs +experiment=missing_key&lt;/code&gt; and &lt;code&gt;hydra-test -cd configs +experiment=wrong_type&lt;/code&gt; to see some
nice errors from pydantic telling you about a missing key and a wrong type of the configuration value, respectively.
By the way, also passing the port parameter wrong, e.g. with &lt;code&gt;db.port=72&lt;/code&gt;, would have triggered the same exception, so 
the configuration via the &lt;span class="caps"&gt;CLI&lt;/span&gt; and &lt;span class="caps"&gt;YAML&lt;/span&gt; share the same checks and validations. &lt;a href="https://hydra.cc/"&gt;Hydra&lt;/a&gt; and &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt; work nicely together 
to make this possible and &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt; greatly extends the validation capabilities of &lt;a href="https://omegaconf.readthedocs.io/"&gt;OmegaConf&lt;/a&gt;, which Hydra uses
as default. Just remember to use the &lt;code&gt;dataclass&lt;/code&gt; from &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt;, not the standard library
and call &lt;code&gt;OmegaConf.to_object(cfg)&lt;/code&gt; at the start of your application to fail as early as&amp;nbsp;possible.&lt;/p&gt;
&lt;p&gt;Hydra has many more, really nice features. Imagine you want to run now the experiments &lt;code&gt;exp1&lt;/code&gt; and &lt;code&gt;exp2&lt;/code&gt; consecutively,
you can just use the &lt;code&gt;--multirun&lt;/code&gt; feature, or &lt;code&gt;-m&lt;/code&gt; for&amp;nbsp;short:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;hydra-test -m -cd configs +experiment&lt;span class="o"&gt;=&lt;/span&gt;exp1,exp2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Or in case you have hundreds of experiments, you can also use globbing&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;hydra-test -m -cd configs &lt;span class="s2"&gt;&amp;quot;+experiment=glob(exp*)&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There&amp;#8217;s so much more to Hydra and several plugins even for hyperparameter optimization exist. Also note that with the
flag &lt;code&gt;--hydra-help&lt;/code&gt;, you can see the hydra-specific parameters of your application. Using just &lt;code&gt;--help&lt;/code&gt; returns some
automatic generated help according to the configuration of your application. This can of course be customized easily with
the help of a powerful templating system as described in &lt;a href="https://hydra.cc/docs/1.0/configure_hydra/app_help/"&gt;Customizing Application&amp;#8217;s help docs&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Hydra makes configuration by &lt;span class="caps"&gt;CLI&lt;/span&gt;, &lt;span class="caps"&gt;YAML&lt;/span&gt; and environment variables a bliss and the time for learning Hydra is well invested
as your application&amp;#8217;s codebase will be more flexible configurable, less complex and therefore more&amp;nbsp;robust.&lt;/p&gt;</content><category term="post"></category><category term="python"></category><category term="configuration"></category><category term="production"></category></entry><entry><title>Matrix Factorization for Collaborative Filtering Is Just Solving an Adjoint Latent Dirichlet Allocation Model After All</title><link href="https://florianwilhelm.info/2021/09/mf_for_collaborative_filtering_is_just_solving_an_adjoint_lda_model/" rel="alternate"></link><published>2021-09-24T17:00:00+02:00</published><updated>2021-09-24T17:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2021-09-24:/2021/09/mf_for_collaborative_filtering_is_just_solving_an_adjoint_lda_model/</id><summary type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)"&gt;Matrix factorization-based methods&lt;/a&gt; are among the most popular methods for collaborative filtering tasks with &lt;a href="https://en.wikipedia.org/wiki/Relevance_feedback"&gt;implicit feedback&lt;/a&gt;. 
The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. 
Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)"&gt;Matrix factorization-based methods&lt;/a&gt; are among the most popular methods for collaborative filtering tasks with &lt;a href="https://en.wikipedia.org/wiki/Relevance_feedback"&gt;implicit feedback&lt;/a&gt;. 
The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. 
Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly important requirement. 
In this work, we provide a theoretical link between unconstrained and the interpretable &lt;a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization"&gt;non-negative matrix factorization&lt;/a&gt; in terms of the personalized ranking induced by these methods. 
We also introduce a novel, &lt;a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"&gt;latent Dirichlet allocation&lt;/a&gt;-inspired model for recommenders and extend our theoretical link to 
also allow the interpretation of an unconstrained matrix factorization as an adjoint formulation of our new model. 
Our experiments indicate that this novel approach represents the unknown processes of implicit user-item interactions in 
the real world much better than unconstrained matrix factorization while being&amp;nbsp;interpretable.&lt;/p&gt;
&lt;p&gt;This paper was presented at the 15th &lt;span class="caps"&gt;ACM&lt;/span&gt; Conference on Recommender Systems (&lt;a href="https://recsys.acm.org/recsys21/"&gt;RecSys 2021&lt;/a&gt;) in Amsterdam. 
A &lt;a href="https://dl.acm.org/doi/fullHtml/10.1145/3460231.3474266#"&gt;pre-recorded video of my presentation&lt;/a&gt; is generously provided by &lt;span class="caps"&gt;ACM&lt;/span&gt; and also the &lt;a href="https://www.slideshare.net/FlorianWilhelm2/matrix-factorization-for-collaborative-filtering-is-just-solving-an-adjoint-latent-dirichlet-allocation-model-after-all"&gt;slides&lt;/a&gt; are available. 
The recording of the presentation at RecSys22 is available&amp;nbsp;here:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/b0HKLfKKDpo'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="data science"></category><category term="recommender systems"></category></entry><entry><title>Handling Anaconda without getting Constricted</title><link href="https://florianwilhelm.info/2021/09/Handling_Anaconda_without_getting_constricted/" rel="alternate"></link><published>2021-09-01T08:00:00+02:00</published><updated>2021-09-01T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2021-09-01:/2021/09/Handling_Anaconda_without_getting_constricted/</id><summary type="html">&lt;p&gt;Miniforge is a Miniconda alternative that allows you to engage in commercial activities without an Anaconda&amp;nbsp;licence.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Commercial Activities using the Anaconda&amp;nbsp;Repository&lt;/h2&gt;
&lt;p&gt;In April 2020, &lt;a href="https://www.anaconda.com/"&gt;Anaconda Inc.&lt;/a&gt;, the company behind our beloved Anaconda distribution, started to change their 
&lt;a href="https://www.anaconda.com/terms-of-service"&gt;Terms of Service&lt;/a&gt; (ToS) in a way that most commercial usage is no longer for free. Peter Wang explained the reasons for
this change in a &lt;a href="https://www.anaconda.com/blog/sustaining-our-stewardship-of-the-open-source-data-science-community"&gt;blog post&lt;/a&gt;. There was a bit of turmoil in the Anaconda community, also about the interpretation of the 
ToS at that time. In October 2020, the ToS was updated and some clarifications were given in an official &lt;a href="https://www.anaconda.com/blog/anaconda-commercial-edition-faq"&gt;&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt; by Stephen&amp;nbsp;Nolan. &lt;/p&gt;
&lt;p&gt;I am no lawyer, so take my words with a grain of salt. My take-way from the ToS is that whenever you are using the Anaconda
repository in commercial activities as a company, you must purchase a licence. This is fair enough since the employees at 
Anaconda Inc. do a hell of a great job, and they need to make a living of course. Thus, if you use Anaconda, and it helps you
as an enterprise, why not just support it? Just do it and stop&amp;nbsp;reading. &lt;/p&gt;
&lt;p&gt;That being said, there might be cases, let&amp;#8217;s say you are working as a freelancer for another company and want to use 
&lt;a href="https://docs.conda.io/en/latest/"&gt;conda&lt;/a&gt;, the package manager of Anaconda, as part of your usual tool chain. Surely, you are not gonna ask the company to
go and buy a license, just because you like to use it in your project. So what legal option do you have besides the obvious
one of not using it and resorting to some &lt;a href="https://virtualenv.pypa.io/"&gt;virtualenv&lt;/a&gt;/&lt;a href="https://pip.pypa.io/"&gt;pip&lt;/a&gt;-based&amp;nbsp;approach?&lt;/p&gt;
&lt;h2&gt;Miniconda Alternative for Commercial&amp;nbsp;Activities&lt;/h2&gt;
&lt;p&gt;As a heavy conda user, you surely know &lt;a href="https://conda-forge.org/"&gt;conda-forge&lt;/a&gt;, a community-led collection of recipes, build infrastructure and 
distributions for the conda package manager. In most cases, you would download &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; install &lt;a href="https://docs.conda.io/en/latest/miniconda.html"&gt;Miniconda&lt;/a&gt;, which uses the Anaconda
repository as &lt;em&gt;defaults&lt;/em&gt; channel, and add conda-forge as an additional channel in case a package is not in the defaults&amp;nbsp;channel.&lt;/p&gt;
&lt;p&gt;What many users of conda-forge don&amp;#8217;t know, is that it encompasses not only additional packages but also almost all packages
of the Anaconda repository (aka the &lt;em&gt;defaults&lt;/em&gt; channel) itself. With this in mind and the fact that conda-forge has no restrictions for commercial activities, you can just remove the &lt;em&gt;defaults&lt;/em&gt;
channel which uses the Anaconda repository (i.e. anaconda.com) from your conda configuration and use only the conda-forge 
repository (i.e. anaconda.org) instead to be legally on the safe side! More information can be found in 
the &lt;a href="https://conda-forge.org/blog/posts/2020-11-20-anaconda-tos/"&gt;conda-forge statement about Anaconda&amp;#8217;s ToS&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;To make the aforementioned channel configuration even easier, the &lt;a href="https://github.com/conda-forge/miniforge"&gt;Miniforge&lt;/a&gt; project can be used as an drop-in replacement for Miniconda, 
that automatically has set up everything for you. Nice! And while you are about to make a change to your installation scripts
anyway, why not directly try &lt;a href="https://github.com/conda-forge/miniforge#mambaforge"&gt;Mambaforge&lt;/a&gt; that comes with &lt;a href="https://github.com/mamba-org/mamba"&gt;mamba&lt;/a&gt;, a faster alternative to &lt;a href="https://docs.conda.io/en/latest/"&gt;conda&lt;/a&gt;, by&amp;nbsp;default.&lt;/p&gt;
&lt;p&gt;To sum this up. It&amp;#8217;s really not that hard to legally use the power of the conda package manager in commercial activities for&amp;nbsp;free.&lt;/p&gt;</content><category term="post"></category><category term="production"></category><category term="Python"></category></entry><entry><title>Using Google BigQuery with Programmatic SQL</title><link href="https://florianwilhelm.info/2021/08/using_bigquery_with_programmatic_sql/" rel="alternate"></link><published>2021-08-08T08:00:00+02:00</published><updated>2021-08-08T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2021-08-08:/2021/08/using_bigquery_with_programmatic_sql/</id><summary type="html">&lt;p&gt;An often encountered Antipattern in Python code are complex queries composed with the help of string substitutions and concatenations. SQLAlchemy Core allows you to generate queries in a programmatic way for many &lt;span class="caps"&gt;SQL&lt;/span&gt; databases like&amp;nbsp;BigQuery.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Especially in data science projects, Python code is often peppered with functions generating &lt;span class="caps"&gt;SQL&lt;/span&gt; queries as strings&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_sku_ts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entity_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sku&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Union&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Compose query to retrieve timeseries for SKU or list of SKUs&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    SELECT *&lt;/span&gt;
&lt;span class="s2"&gt;    FROM `sku-table`&lt;/span&gt;
&lt;span class="s2"&gt;    WHERE entity_id = &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;entity_id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sku&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; AND sku = &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;sku&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt; &amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sku&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;list_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;, &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sku&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; AND sku IN (&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;list_str&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;) &amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    ORDER BY date ASC&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And this is even only a simple example. Using dynamic joins and sub-queries, things can get even more complicated.
When the Python on-board resources are no longer sufficient, some developers start using templating engines like &lt;a href="https://jinja.palletsprojects.com/"&gt;Jinja&lt;/a&gt;
to handle the complexity of generating a query string&amp;nbsp;dynamically. &lt;/p&gt;
&lt;p&gt;But is string generation really the right way to solve a problem like that? It&amp;#8217;s definitely easy as most developers in
the field of data science know their &lt;span class="caps"&gt;SQL&lt;/span&gt; and dealing with strings, so it&amp;#8217;s a start with low entry hurdle. Let&amp;#8217;s shed some
light on the downsides of this approach. The first thing to note is that we have a language break as we use &lt;span class="caps"&gt;SQL&lt;/span&gt; and Python
side-by-side in the same program. This causes us some trouble as we never know if the queries we generate are even 
syntactically valid. Only at execution time we will see if the &lt;span class="caps"&gt;SQL&lt;/span&gt; parsers swallows what we generated which makes unit testing
such functions quite hard. Without an &lt;span class="caps"&gt;SQL&lt;/span&gt; parser, we can only test in the function above if different kinds of parameters lead
to some string, which is trivial. Another impact of the language break is that structuring and decoupling the code becomes harder.
Imagine you want to write one method that takes another query and adds time-based slicing by specifying two dates. If
the query is a string this will be pretty hard as you need to add some &lt;code&gt;DATE(timestamp) BETWEEN FROM_DATE AND TO_DATE&lt;/code&gt;-clause
and there might be already some other where-clauses specified. A last downside is that specifying &lt;span class="caps"&gt;SQL&lt;/span&gt; queries like
this is quite prone to &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt; injection attacks&lt;/a&gt;. So if you compose your queries based on user-generated data, e.g. user input
from some e-commerce website, a malicious user might inject sub-queries in a smart way to steal your data. In many data science
related projects this might be a rather academic vector of attack, but especially in learning-to-rank use-cases it might not
be that&amp;nbsp;unrealistic.&lt;/p&gt;
&lt;p&gt;To summarize these&amp;nbsp;downsides:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;language gap between Python and &lt;span class="caps"&gt;SQL&lt;/span&gt;, i.e. no &lt;span class="caps"&gt;IDE&lt;/span&gt;-support to find errors before&amp;nbsp;execution, &lt;/li&gt;
&lt;li&gt;hard to write clean, decoupled, well-structured code and meaningful unit&amp;nbsp;tests,&lt;/li&gt;
&lt;li&gt;the possibility of &lt;span class="caps"&gt;SQL&lt;/span&gt; injection&amp;nbsp;attacks.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Programmatic &lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;But &lt;span class="caps"&gt;SQL&lt;/span&gt; is the right tool for this task! So what&amp;#8217;s the solution then?&amp;#8221;, I hear you mutter. Welcome to programmatic &lt;span class="caps"&gt;SQL&lt;/span&gt;!
And it might not even be new to you if you have ever used &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt;. In Spark you have many frontends besides the &lt;span class="caps"&gt;SQL&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;, 
like PySpark for Python and others for Java, Scala, R, etc. Most data scientists naturally use a 
programmatic approach in their programs avoiding the downsides of &lt;span class="caps"&gt;SQL&lt;/span&gt; string generation without even&amp;nbsp;noticing. &lt;/p&gt;
&lt;p&gt;But what if we are dealing not with Spark but another database or warehouse like &lt;a href="https://cloud.google.com/bigquery"&gt;BigQuery&lt;/a&gt;? In this case we can
use &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;! SQLAlchemy comes with two abstraction layers, a &lt;em&gt;Core&lt;/em&gt; layer and a high-level &lt;em&gt;&lt;span class="caps"&gt;ORM&lt;/span&gt;&lt;/em&gt; layer. &lt;span class="caps"&gt;ORM&lt;/span&gt; stands for
Object-Relational Mapping and is a common technique to define objects that are automatically mapped to a relational database. 
For most data science projects it&amp;#8217;s not so useful as typical use-cases are analytical and are thus not focused on single instances/objects. 
The underrated Core layer of SQLAlchemy, on the other hand, is really useful as it provides us with a way of generating queries programmatically similar to PySpark.
SQLAlchemy is independent of the actual &lt;span class="caps"&gt;SQL&lt;/span&gt; dialect and by installing a corresponding dialect it can deal with all popular
databases and data warehouses, for instance MySQL, PostgreSQL, BigQuery, etc.
So how does this work? Let&amp;#8217;s go through this with a BigQuery example as it is often used in data science&amp;nbsp;projects.&lt;/p&gt;
&lt;h2&gt;SQLAlchemy with&amp;nbsp;BigQuery&lt;/h2&gt;
&lt;p&gt;Let&amp;#8217;s say we want to find out how many monthly downloads some project on &lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt; has. If you want to follow along and
try it out yourself, a Jupyter notebook is available on my &lt;a href="https://github.com/FlorianWilhelm/bigquery-programmatic-sql"&gt;Github repository&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;With plain &lt;span class="caps"&gt;SQL&lt;/span&gt;, we would solve this task the following&amp;nbsp;way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;google.cloud&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;bigquery&lt;/span&gt;

&lt;span class="n"&gt;bqclient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bigquery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;query_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;SELECT &lt;/span&gt;
&lt;span class="s2"&gt;  DATE_TRUNC(DATE(timestamp), MONTH) AS `month`,&lt;/span&gt;
&lt;span class="s2"&gt;  COUNT(*) AS num_downloads,&lt;/span&gt;
&lt;span class="s2"&gt;FROM `bigquery-public-data.pypi.file_downloads`&lt;/span&gt;
&lt;span class="s2"&gt;WHERE file.project = &amp;#39;pyscaffold&amp;#39;&lt;/span&gt;
&lt;span class="s2"&gt;    AND details.installer.name = &amp;#39;pip&amp;#39;&lt;/span&gt;
&lt;span class="s2"&gt;    AND DATE(timestamp) BETWEEN DATE(&amp;#39;2021-01-01&amp;#39;) AND CURRENT_DATE()&lt;/span&gt;
&lt;span class="s2"&gt;GROUP BY `month`&lt;/span&gt;
&lt;span class="s2"&gt;ORDER BY `month`&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;bqclient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_dataframe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;create_bqstorage_client&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Quite easy, but note that to keep this example focused, the query string is static, meaning that in order to dynamically
change the time slicing, the project name etc., we would have to introduce string substitutions at least. This would
result in the aforementioned&amp;nbsp;downsides.&lt;/p&gt;
&lt;p&gt;In contrast to that, after having installed &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt; and the BigQuery dialect &lt;a href="https://pypi.org/project/pybigquery/"&gt;pybigquery&lt;/a&gt;, we can define a 
dynamic &lt;code&gt;query&lt;/code&gt; object instead of &lt;code&gt;query_string&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.sql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.engine&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;create_engine&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.schema&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;

&lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_engine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bigquery://my_gcp_project&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bigquery-public-data.pypi.file_downloads&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MetaData&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;autoload&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;date_trunc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;timestamp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;num_downloads&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;
           &lt;span class="n"&gt;from_obj&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;and_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;timestamp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;between&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;2021-01-01&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;current_date&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
            &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;file.project&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;pyscaffold&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;details.installer.name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;pip&amp;quot;&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;order_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At first sight, it looks somewhat more verbose and unfamiliar, but you will get used to the SQLAlchemy &lt;span class="caps"&gt;API&lt;/span&gt;, even if 
it doesn&amp;#8217;t look as concise as the one of PySpark, I have to admit. More or less, it&amp;#8217;s just &lt;span class="caps"&gt;SQL&lt;/span&gt; but embedded nicely as functions and objects in&amp;nbsp;Python.&lt;/p&gt;
&lt;p&gt;So far, we have only generated the query and SQLAlchemy would have directly informed us if this was invalid. To see how
the prepared &lt;span class="caps"&gt;SQL&lt;/span&gt; statement looks like, maybe for debugging, we can just &lt;code&gt;print(query)&lt;/code&gt; to&amp;nbsp;get:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;date_trunc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;num_downloads&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;bigquery&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;public&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pypi&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;file_downloads&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;BETWEEN&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;date_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="k"&gt;CURRENT_DATE&lt;/span&gt; 
  &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;project_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; 
  &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;installer&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;installer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; 
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To see the actual query with all literals bound to their final values, we need to compile the query first before&amp;nbsp;printing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;compile_kwargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;literal_binds&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;to&amp;nbsp;get:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;date_trunc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;num_downloads&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;bigquery&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;public&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pypi&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;file_downloads&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;BETWEEN&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="k"&gt;CURRENT_DATE&lt;/span&gt; 
  &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pyscaffold&amp;#39;&lt;/span&gt; 
  &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;installer&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pip&amp;#39;&lt;/span&gt; 
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt; 
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="k"&gt;month&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But this is only interesting for debugging and also for learning SQLAlchemy. In order to execute the query object and transform
its result set into a dataframe, all we have to do&amp;nbsp;is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Quite easy, right? &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; understands and works nicely with SQLAlchemy query objects and&amp;nbsp;engines.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have seen how &lt;span class="caps"&gt;SQL&lt;/span&gt; string generation in Python programs can be replaced by a programmatic approach and that this
approach has several advantages over the usage of strings. But it also comes with some small downsides. First of all, one
has to learn SQLAlchemy, and its &lt;span class="caps"&gt;API&lt;/span&gt; as well as documentation is surely not as nice as PySpark. So when switching, you
will become slower for a while until you get the hang of SQLAlchemy. The second downside is that another level of abstraction,
naturally comes with less control over the final &lt;span class="caps"&gt;SQL&lt;/span&gt; statement, but this is also true for PySpark and a trade-off every developer
always needs to consider. Having mentioned Spark again, my 5 cents are that the PySpark &lt;span class="caps"&gt;API&lt;/span&gt; is much better than SQLAlchemy 
and if you are using Spark anyway, you should rather use Google&amp;#8217;s &lt;a href="https://github.com/GoogleCloudDataproc/spark-bigquery-connector"&gt;Spark Bigquery Connector&lt;/a&gt;. For rather small-data projects,
where your Python program just uses BigQuery as data storage, using SQLAlchemy might up your Python code quite a bit&amp;nbsp;though.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;REMARK&lt;/span&gt;: Spark BigQuery Connector and Pushdowns to&amp;nbsp;BigQuery&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Right now the &lt;a href="https://github.com/GoogleCloudDataproc/spark-bigquery-connector"&gt;Spark Bigquery Connector&lt;/a&gt; has no full pushdown capabilities regarding BigQuery. If &lt;code&gt;pushAllFilters&lt;/code&gt; is set
to true in &lt;code&gt;spark.conf&lt;/code&gt;, which is the default, the connector pushes all the filters Spark can delegate to the BigQuery Storage &lt;span class="caps"&gt;API&lt;/span&gt;. 
Since GroupBy is a more complex operation, the following&amp;nbsp;query:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;spark&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bigquery&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bigquery-public-data.pypi.file_downloads&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;will first fetch all data from the table into Spark. As this might be quite inefficient it&amp;#8217;s better to directly provide an &lt;span class="caps"&gt;SQL&lt;/span&gt;
query that filters and groups direclty in BigQuery&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;spark&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bigquery&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this case, the programmatic SQLAlchemy approach as described above, can also be applied to generate &lt;code&gt;sql_string&lt;/code&gt; with the
advantages described&amp;nbsp;above.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Feedback is always welcome! Please let me know if this was helpful and also if you think otherwise in the comments&amp;nbsp;below.&lt;/p&gt;</content><category term="post"></category><category term="python"></category><category term="production"></category><category term="data science"></category></entry></feed>