<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Florian Wilhelm's blog - talk</title><link href="https://florianwilhelm.info/" rel="alternate"></link><link href="https://florianwilhelm.info/feeds/talk.atom.xml" rel="self"></link><id>https://florianwilhelm.info/</id><updated>2024-09-25T08:00:00+02:00</updated><entry><title>Showcasing Snowflake’s Cortex AI capabilities with the Arctic LLM</title><link href="https://florianwilhelm.info/2024/05/snowinstructor/" rel="alternate"></link><published>2024-05-22T08:00:00+02:00</published><updated>2024-09-25T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2024-05-22:/2024/05/snowinstructor/</id><summary type="html">&lt;p&gt;See how we won the Devpost Hackathon with our submission Snow Instructor, showcasing how you can easily build an &lt;span class="caps"&gt;AI&lt;/span&gt; application with Streamlit, Snowflake and its Cortex &lt;span class="caps"&gt;AI&lt;/span&gt;&amp;nbsp;capabilities.&lt;/p&gt;</summary><content type="html">&lt;p&gt;For the &lt;a href="https://arctic-streamlit-hackathon.devpost.com/"&gt;The Future of &lt;span class="caps"&gt;AI&lt;/span&gt; is Open - Devpost Hackathon&lt;/a&gt;, I led a small team at &lt;a href="https://inovex.de/en/"&gt;inovex&lt;/a&gt; and was the main contributor for our submission &lt;a href="https://devpost.com/software/snow-instructor/"&gt;Snow Instructor&lt;/a&gt;. It was inspired by the quiz show &amp;#8220;Who Wants to Be a Millionaire?&amp;#8221; and the fact that our team was looking for a fun way to learn and test their Snowflake knowledge. We also drew inspiration from real-world &lt;span class="caps"&gt;AI&lt;/span&gt; and Streamlit applications, as we wanted to combine common components into an easy-to-understand application that could be used for learning purposes by exploring the source&amp;nbsp;code.&lt;/p&gt;
&lt;p&gt;Our application crawls the Snowflake documentation at &lt;a href="https://docs.snowflake.com/en/"&gt;https://docs.snowflake.com/en/&lt;/a&gt; and saves it in a Snowflake table. This is done in an initialization step. The actual Snow Instructor app is now a &lt;a href="https://streamlit.io/"&gt;Streamlit&lt;/a&gt; app that reads a page from the stored Snowflake documentation and passes it to the Artic &lt;span class="caps"&gt;LLM&lt;/span&gt; to generate a question. This question is now presented to the user as a quiz with four possible answers to choose from. The user selects an answer and is rewarded with points and snappy comments from the game master&amp;nbsp;:-)&lt;/p&gt;
&lt;p&gt;We used the cookiecutter template &lt;a href="https://github.com/FlorianWilhelm/the-hatchlor"&gt;hatchlor&lt;/a&gt; to start our Python project with a modern setup and common best practices. Then we used scrapy to scrape the Snowflake documentation, markdownify to shrink the &lt;span class="caps"&gt;HTML&lt;/span&gt; pages without losing semantic information, typer and hatch to create command line scripts for the setup, the Snowflake &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Snowpark Python &lt;span class="caps"&gt;API&lt;/span&gt; to access Snowflake, Snowpark as well as the Cortex functions, especially Artic, and finally Streamlit to link everything together. We also used the Snowflake &lt;span class="caps"&gt;CLI&lt;/span&gt; to make the deployment of the app on Snowflake really&amp;nbsp;easy.&lt;/p&gt;
&lt;p&gt;We are very proud that our app demonstrates the key components of an &lt;span class="caps"&gt;AI&lt;/span&gt;-based app to the user in a simple and fun way. Since our project setup utilizes the latest best-practice development methodologies as well as Snowflake features and tools, we provide a holistic yet simple overview of what is possible with Snowflake and Streamlit. We&amp;#8217;d also like to mention a few special tidbits, such as prefetching quiz questions using concurrent.futures and various advanced Streamlit features to top it all off&amp;nbsp;:-)&lt;/p&gt;
&lt;p&gt;Check out the source code on &lt;a href="https://github.com/FlorianWilhelm/snow-instructor/"&gt;Github&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/2kQaZiplSDw'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="python"></category><category term="ai"></category><category term="snowflake"></category><category term="ml"></category></entry><entry><title>Streamlining Python Development: A Guide to a Modern Project Setup</title><link href="https://florianwilhelm.info/2024/04/streamlining_python_development/" rel="alternate"></link><published>2024-04-22T08:00:00+02:00</published><updated>2024-09-25T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2024-04-22:/2024/04/streamlining_python_development/</id><summary type="html">&lt;p&gt;In this blogpost, we&amp;#8217;ll explore tools like Hatch, mypy, and ruff, and dive into efficient project setups. Perfect for Python&amp;nbsp;beginners!&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the dynamic world of Python programming, an efficient project setup is key to success. Although our beloved Python emphasizes &lt;em&gt;There should be one&amp;#8212; and preferably only one &amp;#8212;obvious way to do it.&lt;/em&gt; in its Zen, we all know that it&amp;#8217;s rather Perl&amp;#8217;s &lt;em&gt;There Is More Than One Way To Do It!&lt;/em&gt; when it comes to the nuts and bolts of a Python Package, like packaging, environment &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; dependency management, etc.
In my talk, which was presented at &lt;a href="https://pretalx.com/pyconde-pydata-2024/talk/CBVTEG/"&gt;PyConDE/PyData Berlin 2024&lt;/a&gt;, I demystify the process of setting up a Python project with clarity and efficiency. I&amp;#8217;ll introduce &lt;a href="https://hatch.pypa.io/"&gt;Hatch&lt;/a&gt;, a cutting-edge tool that simplifies project management. We&amp;#8217;ll delve into the functionalities and benefits of using pyproject.toml, a cornerstone in modern Python development for its streamlined approach to project&amp;nbsp;configuration.&lt;/p&gt;
&lt;p&gt;The talk will also cover effective strategies for organizing your project&amp;#8217;s directory structure, ensuring a clean and manageable workspace. Understanding the importance of testing, we&amp;#8217;ll discuss unit testing techniques for enhancing code reliability. Additionally, the presentation will feature mypy for type checking, an essential practice for catching errors early and improving code quality. Finally, we&amp;#8217;ll explore the use of ruff, a modern linter, to keep your code clean and in line with Python&amp;nbsp;standards.&lt;/p&gt;
&lt;p&gt;By the end of this presentation, you will have gained a comprehensive understanding of the tools and methodologies necessary for a modern Python project setup, empowering them to create well-structured, high-quality Python&amp;nbsp;applications.&lt;/p&gt;
&lt;p&gt;Check out the &lt;a href="https://www.youtube.com/watch?v=Qwu11p41YF0"&gt;video of the presentation&lt;/a&gt;, as well as the &lt;a href="https://florianwilhelm.info/documents/slides_streamlining_python_development.pdf"&gt;slides&lt;/a&gt; and the Cookiecutter template &lt;a href="https://github.com/FlorianWilhelm/the-hatchlor"&gt;The Hatchlor&lt;/a&gt; that sets up a Python project just like presented in this&amp;nbsp;talk!&lt;/p&gt;</content><category term="talk"></category><category term="python"></category><category term="configuration"></category><category term="programming"></category><category term="template"></category></entry><entry><title>Forget about AI and do Mathematical Modelling instead!</title><link href="https://florianwilhelm.info/2022/10/forget_about_ai_and_do_mathematical_modelling_instead/" rel="alternate"></link><published>2022-10-16T08:00:00+02:00</published><updated>2022-10-16T08:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2022-10-16:/2022/10/forget_about_ai_and_do_mathematical_modelling_instead/</id><summary type="html">&lt;p&gt;The term artificial intelligence (&lt;span class="caps"&gt;AI&lt;/span&gt;) seems to be ubiquitous these days. It seems that anything can and should be solved using &lt;span class="caps"&gt;AI&lt;/span&gt; but does it really make sense to use neural networks for every&amp;nbsp;use-case?&lt;/p&gt;</summary><content type="html">&lt;p&gt;The term artificial intelligence (&lt;span class="caps"&gt;AI&lt;/span&gt;) seems to be ubiquitous these days. It is being used or is supposed to be used, in almost all areas to automate processes, perform difficult tasks or to help us make decisions.
In my talk, which was presented at &lt;a href="https://codetalks.de/program#talk-1118?event=7"&gt;Code.Talks 2022&lt;/a&gt;, I invite you to take a look behind the hype around &lt;span class="caps"&gt;AI&lt;/span&gt;. From my practical experiences as a data scientist, I will show you that many relevant use-cases can be solved without &lt;span class="caps"&gt;AI&lt;/span&gt;,
just by applying some old-school &lt;em&gt;mathematical modelling&lt;/em&gt;. You will see the many advantages of mathematical modelling like interpretability, data-efficiency, robustness, etc.
over &lt;span class="caps"&gt;AI&lt;/span&gt;-based approaches. The main take-away is that you should always focus on understanding the problem itself before you choose a method - be it a neural network or linear regression - to solve&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;The slides are available on &lt;a href="https://www.slideshare.net/FlorianWilhelm2/forget-about-ai-and-do-mathematical-modelling-instead"&gt;SlideShare&lt;/a&gt; and a podcast episode about the same topic is available on &lt;a href="https://digital-future.podigee.io/13-neue-episode#t=2"&gt;Digital Future&lt;/a&gt;, the &lt;a href="https://www.inovex.de/en/"&gt;inovex&lt;/a&gt; podcast, in&amp;nbsp;German.&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/S_vefzluy4o'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="data science"></category><category term="mathematics"></category><category term="ai"></category></entry><entry><title>Matrix Factorization for Collaborative Filtering Is Just Solving an Adjoint Latent Dirichlet Allocation Model After All</title><link href="https://florianwilhelm.info/2021/09/mf_for_collaborative_filtering_is_just_solving_an_adjoint_lda_model/" rel="alternate"></link><published>2021-09-24T17:00:00+02:00</published><updated>2021-09-24T17:00:00+02:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2021-09-24:/2021/09/mf_for_collaborative_filtering_is_just_solving_an_adjoint_lda_model/</id><summary type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)"&gt;Matrix factorization-based methods&lt;/a&gt; are among the most popular methods for collaborative filtering tasks with &lt;a href="https://en.wikipedia.org/wiki/Relevance_feedback"&gt;implicit feedback&lt;/a&gt;. 
The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. 
Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)"&gt;Matrix factorization-based methods&lt;/a&gt; are among the most popular methods for collaborative filtering tasks with &lt;a href="https://en.wikipedia.org/wiki/Relevance_feedback"&gt;implicit feedback&lt;/a&gt;. 
The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. 
Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly important requirement. 
In this work, we provide a theoretical link between unconstrained and the interpretable &lt;a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization"&gt;non-negative matrix factorization&lt;/a&gt; in terms of the personalized ranking induced by these methods. 
We also introduce a novel, &lt;a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"&gt;latent Dirichlet allocation&lt;/a&gt;-inspired model for recommenders and extend our theoretical link to 
also allow the interpretation of an unconstrained matrix factorization as an adjoint formulation of our new model. 
Our experiments indicate that this novel approach represents the unknown processes of implicit user-item interactions in 
the real world much better than unconstrained matrix factorization while being&amp;nbsp;interpretable.&lt;/p&gt;
&lt;p&gt;This paper was presented at the 15th &lt;span class="caps"&gt;ACM&lt;/span&gt; Conference on Recommender Systems (&lt;a href="https://recsys.acm.org/recsys21/"&gt;RecSys 2021&lt;/a&gt;) in Amsterdam. 
A &lt;a href="https://dl.acm.org/doi/fullHtml/10.1145/3460231.3474266#"&gt;pre-recorded video of my presentation&lt;/a&gt; is generously provided by &lt;span class="caps"&gt;ACM&lt;/span&gt; and also the &lt;a href="https://www.slideshare.net/FlorianWilhelm2/matrix-factorization-for-collaborative-filtering-is-just-solving-an-adjoint-latent-dirichlet-allocation-model-after-all"&gt;slides&lt;/a&gt; are available. 
The recording of the presentation at RecSys22 is available&amp;nbsp;here:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/b0HKLfKKDpo'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="data science"></category><category term="recommender systems"></category></entry><entry><title>Are you sure about that?! Uncertainty Quantification in AI</title><link href="https://florianwilhelm.info/2019/10/uncertainty_quantification_in_ai/" rel="alternate"></link><published>2019-10-10T18:00:00+02:00</published><updated>2019-12-20T18:00:00+01:00</updated><author><name>Florian Wilhelm</name></author><id>tag:florianwilhelm.info,2019-10-10:/2019/10/uncertainty_quantification_in_ai/</id><summary type="html">&lt;p&gt;With the advent of Deep Learning (&lt;span class="caps"&gt;DL&lt;/span&gt;), the field of &lt;span class="caps"&gt;AI&lt;/span&gt; made a giant leap forward and it is nowadays applied in many industrial use-cases. Especially critical systems like autonomous driving, require that &lt;span class="caps"&gt;DL&lt;/span&gt; methods not only produce a prediction but also state the certainty about the prediction in order …&lt;/p&gt;</summary><content type="html">&lt;p&gt;With the advent of Deep Learning (&lt;span class="caps"&gt;DL&lt;/span&gt;), the field of &lt;span class="caps"&gt;AI&lt;/span&gt; made a giant leap forward and it is nowadays applied in many industrial use-cases. Especially critical systems like autonomous driving, require that &lt;span class="caps"&gt;DL&lt;/span&gt; methods not only produce a prediction but also state the certainty about the prediction in order to assess risks and&amp;nbsp;failure.&lt;/p&gt;
&lt;p&gt;In my talk, I will give an introduction to different kinds of uncertainty, i.e. epistemic and aleatoric. To have a baseline for comparison, the classical method of Gaussian Processes for regression problems is presented. I then elaborate on different &lt;span class="caps"&gt;DL&lt;/span&gt; methods for uncertainty quantification like Quantile Regression, Monte-Carlo Dropout, and Deep Ensembles. The talk is concluded with a comparison of these techniques to Gaussian Processes and the current state of the&amp;nbsp;art.&lt;/p&gt;
&lt;p&gt;This talk was presented at &lt;a href="https://de.pycon.org/"&gt;PyCon.&lt;span class="caps"&gt;DE&lt;/span&gt; &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; PyData Berlin 2019&lt;/a&gt; and &lt;a href="https://bigdataconference.lt/2019/"&gt;Big Data Conference Vilnius 2019&lt;/a&gt;. The slides are available on &lt;a href="https://www.slideshare.net/FlorianWilhelm2/uncertainty-quantification-in-ai"&gt;SlideShare&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
                    &lt;iframe width="800" height="500"
                        src='https://www.youtube.com/embed/LCDIqL-8bHs'
                        frameborder='0' webkitAllowFullScreen
                        mozallowfullscreen allowFullScreen&gt;
                    &lt;/iframe&gt;
                &lt;/span&gt;&lt;/p&gt;</content><category term="talk"></category><category term="python"></category><category term="machine-learning"></category><category term="uncertainty quantification"></category><category term="data science"></category></entry></feed>