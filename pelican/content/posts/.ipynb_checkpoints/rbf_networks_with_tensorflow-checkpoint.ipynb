{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fwilhelm/.virtualenvs/venv3/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprind\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=2)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "target = encoder.fit_transform(mnist.target[:, np.newaxis])\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data / 255, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.677450092787716"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_rbf = 64\n",
    "n_samples = 10000\n",
    "a = np.random.uniform(0, 1, size=(n_samples, n_rbf))\n",
    "b = np.random.uniform(0, 1, size=(n_samples, n_rbf))\n",
    "np.mean(np.sum((a - b)**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self, n_rbf=64):\n",
    "        self.n_hidden = n_rbf\n",
    "        self._graph = tf.Graph()\n",
    "        self.session = None\n",
    "        self._initialized = False\n",
    "\n",
    "    def get_model(self, n_features, means):\n",
    "        with tf.name_scope('input'):\n",
    "            x = tf.placeholder(\"float\", shape=[None, n_features], name='X')\n",
    "        with tf.name_scope('hidden'):\n",
    "            c = [tf.Variable(tf.constant(means[i,:].astype(np.float32), shape=[1, n_features]), name='c')\n",
    "                 for i in range(self.n_hidden)]\n",
    "            r = [tf.Variable([11.0], name=\"beta\")\n",
    "                 for i in range(self.n_hidden)]\n",
    "            h = [tf.exp(-tf.div(tf.reduce_sum(tf.square(tf.sub(x, c[i])), 1, keep_dims=True), tf.square(r[i]))) \n",
    "                 for i in range(self.n_hidden)]           \n",
    "            [tf.histogram_summary(\"c_{}\".format(i), c) for i, c in enumerate(c)]\n",
    "        with tf.name_scope('output'):\n",
    "            a = tf.Variable(tf.truncated_normal([self.n_hidden, 10], stddev=0.1), name='A')\n",
    "            y = tf.nn.softmax(tf.matmul(tf.concat(1, h), a), name='y')\n",
    "            tf.histogram_summary(\"A\", a)\n",
    "            tf.histogram_summary(\"y\", y)\n",
    "        return y\n",
    "\n",
    "    def add_cost(self, yhat):\n",
    "        y = tf.placeholder(\"float\", shape=[None, 10], name='Y')\n",
    "        cross_entropy = -tf.reduce_sum(y * tf.log(yhat))\n",
    "        tf.scalar_summary(\"loss\", cross_entropy)\n",
    "        return cross_entropy\n",
    "\n",
    "    def _init(self, n_features, means):\n",
    "        with self._graph.as_default():\n",
    "            model = self.get_model(n_features, means)\n",
    "            costfunc = self.add_cost(model)\n",
    "            train_a = tf.train.GradientDescentOptimizer(0.01).minimize(\n",
    "                costfunc, var_list=[self.get_var(u'output/A:0')], name='train_a')\n",
    "            train_c = tf.train.GradientDescentOptimizer(0.01).minimize(\n",
    "                costfunc, var_list=self.get_vars('hidden/c'), name='train_c')         \n",
    "            self.session = tf.Session(graph=self._graph)\n",
    "            self._writer = tf.train.SummaryWriter(\"./logs\", self.session.graph_def)\n",
    "            self._saver = tf.train.Saver()\n",
    "            self.session.run(tf.initialize_all_variables())\n",
    "            self._initialized = True\n",
    "                \n",
    "    def save(self, path):\n",
    "        if not self._initialized:\n",
    "            raise RuntimeError(\"Cannot save an uninitialized model\")\n",
    "        with self._graph.as_default():\n",
    "            os.mkdir(path)\n",
    "            self._saver.save(self.session, os.path.join(path, \"checkpoint.data\"))\n",
    "        return self\n",
    "        \n",
    "    def restore(self, path):\n",
    "        if self._initialized:\n",
    "            self.session.close()\n",
    "        self._graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=self._graph)\n",
    "        with self._graph.as_default():\n",
    "            self._saver = tf.train.import_meta_graph(os.path.join(path, \"checkpoint.data.meta\"))\n",
    "            self._saver.restore(self.session, os.path.join(path, \"checkpoint.data\"))\n",
    "        return self\n",
    "    \n",
    "    def get_var(self, name):\n",
    "        return self.get_all_vars()[name]\n",
    "    \n",
    "    def get_vars(self, name):\n",
    "        return [v for k, v in self.get_all_vars().items() if k.startswith(name)]\n",
    "        \n",
    "    def get_op(self, name):\n",
    "        return self._graph.get_operation_by_name(name)\n",
    "    \n",
    "    def get_tensor(self, name):\n",
    "        return self._graph.get_tensor_by_name(name)\n",
    "    \n",
    "    def get_all_vars(self):\n",
    "        with self._graph.as_default():\n",
    "            return {var.name: var for var in tf.all_variables()}\n",
    "                \n",
    "    def fit(self, X, y, steps=50, batch=200):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if not self._initialized:\n",
    "            means = k_means(X, self.n_hidden)[0]\n",
    "            self._init(n_features, means)\n",
    "\n",
    "        pbar = pyprind.ProgBar(steps)\n",
    "        with self._graph.as_default():\n",
    "            merged_summaries = tf.merge_all_summaries()\n",
    "        for step in range(steps):\n",
    "            for _ in range(1000):\n",
    "                batch_indices = np.random.randint(n_samples, size=batch)\n",
    "                self.session.run(self.get_op('train_a'), \n",
    "                                 feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                            self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            for _ in range(1000):\n",
    "                batch_indices = np.random.randint(n_samples, size=batch)\n",
    "                self.session.run(self.get_op('train_c'), \n",
    "                                 feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                            self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            summaries = self.session.run(merged_summaries,                                 \n",
    "                                         feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                                    self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            self._writer.add_summary(summaries, step)\n",
    "            pbar.update()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.session.run(self.get_tensor('output/y:0'), feed_dict={self.get_tensor('input/X:0'): X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = ANN(n_rbf=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%  100%\n",
      "[#] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0.113035714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:06\n"
     ]
    }
   ],
   "source": [
    "for step in range(1):\n",
    "    ann.fit(X_train, y_train, steps=1, batch=200)\n",
    "    preds = ann.predict(X_train)\n",
    "    print(np.unique(np.argmax(preds, axis=1)))\n",
    "    print(np.sum(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))/preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann.save('model_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann.restore('my_path23')\n",
    "preds = ann.predict(X_train)\n",
    "print(np.unique(np.argmax(preds, axis=1)))\n",
    "print(np.sum(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))/preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    h = ann.h[i].eval(session=ann.session, feed_dict={ann._x: X_train[47820,:][np.newaxis], ann._y: y_train[0,:][np.newaxis]})\n",
    "    print(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
