{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bla\n",
    "\n",
    "[TensorFlow][] from Google is an open source software library for artificial neural\n",
    "networks (esp. deep learning) and there is a lot of buzz around it right now.\n",
    "Some find it [terrific][] while others seem to be quite [disappointed][]. I\n",
    "think that although TensorFlow is not revolutionary as some say, it surely does\n",
    "a lot of things right especially when it comes to the [interface and architecture][].\n",
    "My verdict is that TensorFlow is here to stay and this should mean to every\n",
    "data scientist that it's at least beneficial to become familiar with it.\n",
    "\n",
    "In order to do so, my strategy is always the same. After having read some [basic tutorials][],\n",
    "I pick myself a task that comprises some more advanced features of a library and\n",
    "define a set of achievements I want to fulfill. In order to use TensorFlow as part\n",
    "of a predictive application that could be deployed productively, I need it to be:\n",
    "\n",
    "* comfortable to use similar to a regressor in [Scikit-Learn][],\n",
    "* easy to debug (e.g. visualization of the graph, accessibility of variables etc.) and\n",
    "* able to store a trained network for later usage.\n",
    "\n",
    "The new part for me is that I now write, in the spirit of Einstein's \"You do not really\n",
    "understand something unless you can explain it to your grandmother.\", an article\n",
    "about my learnings and experiences.\n",
    "\n",
    "There are already a lot of neural network examples For TensorFlow to find on the web.\n",
    "Besides its own examples there is [TensorFlow-Examples][] and in terms of Scikit-Learn\n",
    "usage [skflow][] is definitely noteworthy. Mainly to do something different, our\n",
    "task will be to develop an old-school *radial basis function (RBF) network* with TensorFlow.\n",
    "So let's start with the definition what that exactly is. An RBF network is an\n",
    "artificial neural network consisting of three layers, input, output and a hidden\n",
    "layer that uses radial basis functions as activation functions. An RBF is a\n",
    "real-valued function whose value depend only on the radius, i.e. the distance to\n",
    "the origin. So every function $$\\phi$$ satisfying the property\n",
    "$$\\phi(\\mathbf{x}) = \\phi(\\|\\mathbf{x}\\|)$$ is an RBF.\n",
    "\n",
    "<img class=\"noZoom\" src=\"/images/rbf-network.png\" alt=\"Radial basis function network\">\n",
    "\n",
    "\n",
    "$$\\varphi (\\mathbf {x} )=\\sum _{i=1}^{N}a_{i}\\rho (||\\mathbf {x} -\\mathbf {c} _{i}||)$$\n",
    "\n",
    "[TensorFlow]: https://www.tensorflow.org/\n",
    "[terrific]: http://www.kdnuggets.com/2015/12/tensor-flow-terrific-deep-learning-library.html\n",
    "[disappointed]: http://www.kdnuggets.com/2015/11/google-tensorflow-deep-learning-disappoints.html\n",
    "[interface and architecture]: https://github.com/zer0n/deepframeworks/blob/master/README.md\n",
    "[basic tutorials]: https://www.tensorflow.org/versions/master/tutorials/index.html\n",
    "[Scikit-Learn]: http://scikit-learn.org/stable/\n",
    "[California housing dataset]: http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
    "[TensorFlow-Examples]: https://github.com/aymericdamien/TensorFlow-Examples\n",
    "[skflow]: https://github.com/tensorflow/skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprind\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=2)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "target = encoder.fit_transform(mnist.target[:, np.newaxis])\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data / 255, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.677450092787716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_rbf = 64\n",
    "n_samples = 10000\n",
    "a = np.random.uniform(0, 1, size=(n_samples, n_rbf))\n",
    "b = np.random.uniform(0, 1, size=(n_samples, n_rbf))\n",
    "np.mean(np.sum((a - b)**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfdfadsfasd Text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self, n_rbf=64):\n",
    "        self.n_hidden = n_rbf\n",
    "        self._graph = tf.Graph()\n",
    "        self.session = None\n",
    "        self._initialized = False\n",
    "\n",
    "    def get_model(self, n_features, means):\n",
    "        with tf.name_scope('input'):\n",
    "            x = tf.placeholder(\"float\", shape=[None, n_features], name='X')\n",
    "        with tf.name_scope('hidden'):\n",
    "            c = [tf.Variable(tf.constant(means[i,:].astype(np.float32), shape=[1, n_features]), name='c')\n",
    "                 for i in range(self.n_hidden)]\n",
    "            r = [tf.Variable([11.0], name=\"beta\")\n",
    "                 for i in range(self.n_hidden)]\n",
    "            h = [tf.exp(-tf.div(tf.reduce_sum(tf.square(tf.sub(x, c[i])), 1, keep_dims=True), tf.square(r[i]))) \n",
    "                 for i in range(self.n_hidden)]           \n",
    "            [tf.histogram_summary(\"c_{}\".format(i), c) for i, c in enumerate(c)]\n",
    "        with tf.name_scope('output'):\n",
    "            a = tf.Variable(tf.truncated_normal([self.n_hidden, 10], stddev=0.1), name='A')\n",
    "            y = tf.nn.softmax(tf.matmul(tf.concat(1, h), a), name='y')\n",
    "            tf.histogram_summary(\"A\", a)\n",
    "            tf.histogram_summary(\"y\", y)\n",
    "        return y\n",
    "\n",
    "    def add_cost(self, yhat):\n",
    "        y = tf.placeholder(\"float\", shape=[None, 10], name='Y')\n",
    "        cross_entropy = -tf.reduce_sum(y * tf.log(yhat))\n",
    "        tf.scalar_summary(\"loss\", cross_entropy)\n",
    "        return cross_entropy\n",
    "\n",
    "    def _init(self, n_features, means):\n",
    "        with self._graph.as_default():\n",
    "            model = self.get_model(n_features, means)\n",
    "            costfunc = self.add_cost(model)\n",
    "            train_a = tf.train.GradientDescentOptimizer(0.01).minimize(\n",
    "                costfunc, var_list=[self.get_var(u'output/A:0')], name='train_a')\n",
    "            train_c = tf.train.GradientDescentOptimizer(0.01).minimize(\n",
    "                costfunc, var_list=self.get_vars('hidden/c'), name='train_c')         \n",
    "            self.session = tf.Session(graph=self._graph)\n",
    "            self._writer = tf.train.SummaryWriter(\"./logs\", self.session.graph_def)\n",
    "            self._saver = tf.train.Saver()\n",
    "            self.session.run(tf.initialize_all_variables())\n",
    "            self._initialized = True\n",
    "                \n",
    "    def save(self, path):\n",
    "        if not self._initialized:\n",
    "            raise RuntimeError(\"Cannot save an uninitialized model\")\n",
    "        with self._graph.as_default():\n",
    "            os.mkdir(path)\n",
    "            self._saver.save(self.session, os.path.join(path, \"checkpoint.data\"))\n",
    "        return self\n",
    "        \n",
    "    def restore(self, path):\n",
    "        if self._initialized:\n",
    "            self.session.close()\n",
    "        self._graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=self._graph)\n",
    "        with self._graph.as_default():\n",
    "            self._saver = tf.train.import_meta_graph(os.path.join(path, \"checkpoint.data.meta\"))\n",
    "            self._saver.restore(self.session, os.path.join(path, \"checkpoint.data\"))\n",
    "        return self\n",
    "    \n",
    "    def get_var(self, name):\n",
    "        return self.get_all_vars()[name]\n",
    "    \n",
    "    def get_vars(self, name):\n",
    "        return [v for k, v in self.get_all_vars().items() if k.startswith(name)]\n",
    "        \n",
    "    def get_op(self, name):\n",
    "        return self._graph.get_operation_by_name(name)\n",
    "    \n",
    "    def get_tensor(self, name):\n",
    "        return self._graph.get_tensor_by_name(name)\n",
    "    \n",
    "    def get_all_vars(self):\n",
    "        with self._graph.as_default():\n",
    "            return {var.name: var for var in tf.all_variables()}\n",
    "                \n",
    "    def fit(self, X, y, steps=50, batch=200):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if not self._initialized:\n",
    "            means = k_means(X, self.n_hidden)[0]\n",
    "            self._init(n_features, means)\n",
    "\n",
    "        pbar = pyprind.ProgBar(steps)\n",
    "        with self._graph.as_default():\n",
    "            merged_summaries = tf.merge_all_summaries()\n",
    "        for step in range(steps):\n",
    "            for _ in range(1000):\n",
    "                batch_indices = np.random.randint(n_samples, size=batch)\n",
    "                self.session.run(self.get_op('train_a'), \n",
    "                                 feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                            self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            for _ in range(1000):\n",
    "                batch_indices = np.random.randint(n_samples, size=batch)\n",
    "                self.session.run(self.get_op('train_c'), \n",
    "                                 feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                            self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            summaries = self.session.run(merged_summaries,                                 \n",
    "                                         feed_dict={self.get_tensor('input/X:0'): X[batch_indices],\n",
    "                                                    self.get_tensor('Y:0'): y[batch_indices]})\n",
    "            self._writer.add_summary(summaries, step)\n",
    "            pbar.update()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.session.run(self.get_tensor('output/y:0'), feed_dict={self.get_tensor('input/X:0'): X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = ANN(n_rbf=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "0%  100%\n",
      "[#] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0.110928571429\n"
     ]
    }
   ],
   "source": [
    "for step in range(1):\n",
    "    ann.fit(X_train, y_train, steps=1, batch=200)\n",
    "    preds = ann.predict(X_train)\n",
    "    print(np.unique(np.argmax(preds, axis=1)))\n",
    "    print(np.sum(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))/preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ANN at 0x7f5333910cf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.save('model_dir2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0.110928571429\n"
     ]
    }
   ],
   "source": [
    "ann.restore('model_dir2')\n",
    "preds = ann.predict(X_train)\n",
    "print(np.unique(np.argmax(preds, axis=1)))\n",
    "print(np.sum(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))/preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ANN' object has no attribute 'h'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c7a8037eedf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m47820\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ANN' object has no attribute 'h'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    h = ann.h[i].eval(session=ann.session, feed_dict={ann._x: X_train[47820,:][np.newaxis], ann._y: y_train[0,:][np.newaxis]})\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
